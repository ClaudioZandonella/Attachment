# Model Comparison {#model-comparison-ext}

Model comparison allows us to compare multiple hypotheses and identify which is the most supported by the data [@mcelreathStatisticalRethinkingBayesian2020]. First, we need to formalize models according to our hypotheses. Subsequently, we can evaluate which is the most supported model among those considered according to the data using the AIC and BIC [@wagenmakersAICModelSelection2004; @akaike1973a; @schwarzEstimatingDimensionModel1978].

## Formalize Models

Following the same reasons as before (see Section~\@ref(model-choice-ext)), we consider Zero Inflated Negative Binomial Mixed-Effects models. Again, we consider only the role of gender as a fixed effect and children's classroom ID as a random effect for $p$. Whereas, considering $\mu$, we define four different models to take into account the different theoretical perspectives:

- `fit_ext_zero`: we consider only the effect of gender. This model assumes that attachment plays no role.
- `fit_ext_mother`: we consider the additive effects of gender and mother attachment. This model supports the idea that only mother attachment is important (**Monotropy Theory**).
- `fit_ext_additive`: we consider the additive effects of gender,  mother attachment, and father attachment. This model supports the idea that both mother attachment and father attachment are important, but not their interaction (**Hierarchy Theory** or **Independence Theory**).
- `fit_ext_inter`: we consider the additive effects of gender and the interaction between mother attachment and father attachment. This model supports the idea that the interaction between mother attachment and father attachment is important (**Integration Theory**).

Moreover, in all models, we include children's classroom ID as a random effect to take into account teachers' different ability to evaluate children's problems. Using R formula syntax, we have
```{r, echo = TRUE, eval=FALSE}
# formula for p (same for all models)
p ~ gender + (1|ID_class)

# formula for mu

# fit_ext_zero
mu ~ gender + (1|ID_class)

# fit_ext_mother
mu ~ gender + mother + (1|ID_class)

# fit_ext_additive
mu ~ gender + mother + father + (1|ID_class)

# fit_ext_inter
mu ~ gender + mother * father + (1|ID_class)
```

## AIC and BIC Results

After estimating the models, the AIC and BIC values together with their relative weights are computed. Results are reported in Table~\@ref(tab:table-AIC-BIC-weights-ext).

```{r table-AIC-BIC-weights-ext, cache=TRUE}
get_table_AIC_BIC(AIC_weights = AIC_weights_ext,
                  BIC_weights = BIC_weights_ext,
                  problem = "ext",
                  format = params$format,
                  path_img = "images/")
```

According to AIC, the most likely model is `fit_ext_mother` (`r perc_model_ext("fit_ext_mother", "AIC")`\%) and the second most likely model is `fit_ext_additive` (`r perc_model_ext("fit_ext_additive", "AIC")`\%) given the data and the set of models considered. According to BIC, instead,  the most likely model is `fit_ext_zero` (`r perc_model_ext("fit_ext_zero", "BIC")`\%) and the second most likely model is `fit_ext_mother` (`r perc_model_ext("fit_ext_mother", "BIC")`\%) given the data and the set of models considered.

To interpret these results, note that, AIC tends to select more complex models that can better explain the data, on the contrary, BIC penalizes complex models to a greater extent.  As pointed out by @kuhaAICBICComparisons2004, using the two criteria together is always advocated as agreement provides reassurance on the robustness of the results and disagreement still provides useful information for the discussion. We can say that there is evidence in favour of the role of mother attachment but probably this effect is small.

## Selected Model

Considering the model `fit_ext_mother`, we can run an analysis of deviance to evaluate the significance of the predictors.
```{r, echo =TRUE, cache=TRUE}
car::Anova(fit_ext_mother)
```
Results confirm a statistically significant effect of gender and mother attachment. The model summary is reported below.
```{r, echo =TRUE, cache=TRUE}
summary(fit_ext_mother)
```
To evaluate the effect of gender and mother attachment, the marginal predicted values according to gender and mother attachment are presented separately in Figure~\@ref(fig:plot-comparison-effects-ext). Not that the marginal predicted values for gender are averaged over mother attachment. Whereas, the marginal predicted values for mother attachment are averaged over gender.
```{r plot-comparison-effects-ext, cache=TRUE, fig.asp=.65, message=FALSE, fig.cap="Marginal predicted values according to gender and mother attachment ($n_{subj} = 847$)."}
get_plot_zinb(model = fit_ext_mother, attachment = "mother")
```

Post-hoc tests are run to evaluate differences between mother attachment styles, considering pairwise comparisons and adjusting *p*-values according to multivariate *t*-distribution. Results are reported below,
```{r, cache=TRUE, echo = TRUE}
emmeans::contrast(emmeans::emmeans(fit_ext_mother, specs = ~ mother ),
                  "pairwise", adjust = "mvt")
```

Overall, results indicate that Males have more externalizing problems than Females. Regarding mother attachment, Fearful and Avoidant children have more problems than Secure children. Moreover, also the difference between Anxious and Secure children and the difference between Anxious and Fearful children have a low (but not statistically significant) *p*-value.

To evaluate the fit of the model to the data, we computed the *Marginal* $R^2$ and the *Conditional* $R^2$.

```{r, echo=TRUE, message=FALSE, cache=TRUE}
performance::r2(fit_ext_mother)
```

We can see that the actual variance explained by fixed effects is around 7\%, not bad for psychology.

#### Conclusions {-}

Considering attachment theoretical perspectives, results indicate only the role of mother attachment so we can support the **Monotropy Theory**. Note, however, that the compared models contain no information regarding the expected direction of the effects but we only include/exclude predictors.
