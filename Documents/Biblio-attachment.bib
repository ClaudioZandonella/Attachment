
@article{ainsworthAttachmentExplorationSeparation1970a,
  ids = {ainsworthAttachmentExplorationSeparation1970},
  title = {Attachment, Exploration, and Separation: Illustrated by the Behavior of One-Year-Olds in a Strange Situation.},
  author = {Ainsworth, Mary D. and Bell, Silvia M.},
  date = {1970},
  journaltitle = {Child Development},
  volume = {41},
  number = {1},
  pages = {49--67},
  publisher = {{Blackwell Publishing}},
  location = {{United Kingdom}},
  issn = {1467-8624(Electronic),0009-3920(Print)},
  doi = {10.2307/1127388},
  abstract = {Considers the concepts of attachment and attachment behavior from an ethological-evolutionary viewpoint. Attachment behavior and exploration are viewed in balance, and the biological functions of each are discussed. The behavior of 56 white, middle-class infants, 49-51 wk. old in a strange situation was investigated. The presence of the mother encouraged exploratory behavior, her absence depressed exploration and heightened attachment behaviors. In separation episodes such behaviors as crying and search increased. In reunion episodes proximity-seeking and contact-maintaining behaviors were heightened. In a substantial proportion of Ss, contact-resisting behaviors were also heightened in the reunion episodes usually in conjunction with contact-maintaining behaviors, thus suggesting ambivalence. Some Ss also displayed proximity-avoiding behavior in relation to the mother in the reunion episodes. Findings are discussed in the context of relevant observational, clinical, and experimental studies of human and nonhuman primates. (42 ref.) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {*Environment,*Exploratory Behavior,*Familiarity,Mothers}
}

@inproceedings{akaike1973a,
  title = {Information {{Theory}} and an {{Extension}} of the {{Maximum Likelihood Principle}}},
  booktitle = {Proceedings of the {{Second International Symposium}} on {{Information Theory}}},
  author = {Akaike, H.},
  editor = {Petrov, B.N. and Csaki, F.},
  date = {1973-11},
  pages = {267--281},
  publisher = {{Budapest Akademiai Kiado}},
  langid = {english},
  venue = {Budapest}
}

@article{bartlettCommentLindleyStatistical1957,
  title = {A Comment on d. {{V}}. {{Lindley}}'s Statistical Paradox},
  author = {Bartlett, M.},
  date = {1957},
  journaltitle = {Biometrika},
  volume = {44},
  pages = {533--534}
}

@article{bayarriExtendingConventionalPriors2007,
  title = {Extending {{Conventional Priors}} for {{Testing General Hypotheses}} in {{Linear Models}}},
  author = {Bayarri, M. J. and García-Donato, Gonzalo},
  date = {2007},
  journaltitle = {Biometrika},
  volume = {94},
  number = {1},
  eprint = {20441359},
  eprinttype = {jstor},
  pages = {135--152},
  publisher = {{[Oxford University Press, Biometrika Trust]}},
  issn = {00063444, 14643510},
  abstract = {[We consider that observations come from a general normal linear model and that it is desirable to test a simplifying null hypothesis about the parameters. We approach this problem from an objective Bayesian, model-selection perspective. Crucial ingredients for this approach are 'proper objective priors' to be used for deriving the Bayes factors. Jeffreys-Zellner-Siow priors have good properties for testing null hypotheses defined by specific values of the parameters in full-rank linear models. We extend these priors to deal with general hypotheses in general linear models, not necessarily of full rank. The resulting priors, which we call 'conventional priors', are expressed as a generalization of recently introduced 'partially informative distributions'. The corresponding Bayes factors are fully automatic, easily computed and very reasonable. The methodology is illustrated for the change-point problem and the equality of treatments effects problem. We compare the conventional priors derived for these problems with other objective Bayesian proposals like the intrinsic priors. It is concluded that both priors behave similarly although interesting subtle differences arise. We adapt the conventional priors to deal with nonnested model selection as well as multiple-model comparison. Finally, we briefly address a generalization of conventional priors to nonnormal scenarios.]}
}

@article{bergerIntrinsicBayesFactor1996,
  title = {The {{Intrinsic Bayes Factor}} for {{Model Selection}} and {{Prediction}}},
  author = {Berger, James O. and Pericchi, Luis R.},
  date = {1996-03},
  journaltitle = {Journal of the American Statistical Association},
  shortjournal = {Journal of the American Statistical Association},
  volume = {91},
  number = {433},
  pages = {109--122},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.1996.10476668},
  url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1996.10476668},
  urldate = {2021-08-06},
  langid = {english},
  file = {/Users/claudio/MEGA/Zotero/Berger_Pericchi_1996_The Intrinsic Bayes Factor for Model Selection and Prediction.pdf;/Users/claudio/Zotero/storage/XXT58WU7/Berger and Pericchi - 1996 - The Intrinsic Bayes Factor for Model Selection and.pdf}
}

@article{bleiBayesianMixtureModels,
  title = {Bayesian {{Mixture Models}} and the {{Gibbs Sampler}}},
  author = {Blei, David M},
  pages = {10},
  langid = {english},
  file = {/Users/claudio/MEGA/Zotero/Blei_Bayesian Mixture Models and the Gibbs Sampler.pdf;/Users/claudio/Zotero/storage/HNGYXPA7/Blei - Bayesian Mixture Models and the Gibbs Sampler.pdf}
}

@article{boing-messingBayesFactorsTesting2021,
  ids = {boing-messingBayesFactorsTesting2021a},
  title = {Bayes {{Factors}} for {{Testing Order Constraints}} on {{Variances}} of {{Dependent Outcomes}}},
  author = {Böing-Messing, Florian and Mulder, Joris},
  date = {2021-04-03},
  journaltitle = {The American Statistician},
  shortjournal = {The American Statistician},
  volume = {75},
  number = {2},
  pages = {152--161},
  issn = {0003-1305, 1537-2731},
  doi = {10.1080/00031305.2020.1715257},
  url = {https://www.tandfonline.com/doi/full/10.1080/00031305.2020.1715257},
  urldate = {2021-05-11},
  abstract = {In statistical practice, researchers commonly focus on patterns in the means of multiple dependent outcomes while treating variances as nuisance parameters. However, in fact, there are often substantive reasons to expect certain patterns in the variances of dependent outcomes as well. For example, in a repeated measures study, one may expect the variance of the outcome to increase over time if the difference between subjects becomes more pronounced over time because the subjects respond differently to a given treatment. Such expectations can be formulated as order constrained hypotheses on the variances of the dependent outcomes. Currently, however, no methods exist for testing such hypotheses in a direct manner. To fill this gap, we develop a Bayes factor for this challenging testing problem. Our Bayes factor is based on the multivariate normal distribution with an unstructured covariance matrix, which is often used to model dependent outcomes. Order constrained hypotheses can then be formulated on the variances on the diagonal of the covariance matrix. To compute Bayes factors between multiple order constrained hypotheses, a prior distribution needs to be specified under every hypothesis to be tested. Here, we use the encompassing prior approach in which priors under order constrained hypotheses are truncations of the prior under the unconstrained hypothesis. The resulting Bayes factor is fully automatic in the sense that no subjective priors need to be specified by the user.},
  langid = {english},
  file = {/Users/claudio/MEGA/Zotero/Böing-Messing_Mulder_2021_Bayes Factors for Testing Order Constraints on Variances of Dependent Outcomes.pdf;/Users/claudio/Zotero/storage/4TI5Y359/Böing-Messing and Mulder - 2021 - Bayes Factors for Testing Order Constraints on Var.pdf}
}

@book{bowlbyAttachmentLoss1969,
  title = {Attachment and Loss},
  author = {Bowlby, J.},
  date = {1969},
  publisher = {{Basic Books}},
  location = {{New York}}
}

@article{Brenning2014ThePQ,
  title = {The Psychometric Qualities of a Short Version of the {{Experiences}} in {{Close Relationships Scale}} – {{Revised Child}} Version},
  author = {Brenning, Katrijn and Petegem, Stijn Van and Vanhalst, Janne and Soenens, Bart},
  date = {2014},
  journaltitle = {Personality and Individual Differences},
  volume = {68},
  pages = {118--123}
}

@article{brethertonFathersAttachmentTheory2010,
  ids = {brethertonFathersAttachmentTheory2010a},
  title = {Fathers in Attachment Theory and Research: A Review},
  shorttitle = {Fathers in Attachment Theory and Research},
  author = {Bretherton, Inge},
  date = {2010-01},
  journaltitle = {Early Child Development and Care},
  volume = {180},
  number = {1-2},
  pages = {9--23},
  issn = {0300-4430, 1476-8275},
  doi = {10.1080/03004430903414661},
  url = {http://www.tandfonline.com/doi/abs/10.1080/03004430903414661},
  urldate = {2019-01-04},
  langid = {english},
  file = {/Users/claudio/MEGA/Zotero/Bretherton_2010_Fathers in attachment theory and research.pdf;/Users/claudio/Zotero/storage/ENFRAG95/Bretherton_2010_Fathers in attachment theory and research.pdf}
}

@article{brooksGlmmTMBBalancesSpeed2017,
  title = {{{glmmTMB}} Balances Speed and Flexibility among Packages for Zero-Inflated Generalized Linear Mixed Modeling},
  author = {Brooks, Mollie E. and Kristensen, Kasper and van Benthem, Koen J. and Magnusson, Arni and Berg, Casper W. and Nielsen, Anders and Skaug, Hans J. and Maechler, Martin and Bolker, Benjamin M.},
  options = {useprefix=true},
  date = {2017},
  journaltitle = {The R Journal},
  volume = {9},
  number = {2},
  pages = {378--400},
  url = {https://journal.r-project.org/archive/2017/RJ-2017-066/index.html}
}

@article{burknerAdvancedBayesianMultilevel2018a,
  title = {Advanced {{Bayesian Multilevel Modeling}} with the {{R Package}} Brms},
  author = {Bürkner, Paul-Christian},
  date = {2018},
  journaltitle = {The R Journal},
  shortjournal = {The R Journal},
  volume = {10},
  number = {1},
  pages = {395},
  issn = {2073-4859},
  doi = {10.32614/RJ-2018-017},
  url = {https://journal.r-project.org/archive/2018/RJ-2018-017/index.html},
  urldate = {2021-08-10},
  abstract = {The brms package allows R users to easily specify a wide range of Bayesian single-level and multilevel models which are fit with the probabilistic programming language Stan behind the scenes. Several response distributions are supported, of which all parameters (e.g., location, scale, and shape) can be predicted. Non-linear relationships may be specified using non-linear predictor terms or semi-parametric approaches such as splines or Gaussian processes. Multivariate models can be fit as well. To make all of these modeling options possible in a multilevel framework, brms provides an intuitive and powerful formula syntax, which extends the well known formula syntax of lme4. The purpose of the present paper is to introduce this syntax in detail and to demonstrate its usefulness with four examples, each showing relevant aspects of the syntax.},
  langid = {english},
  file = {/Users/claudio/MEGA/Zotero/Bürkner_2018_Advanced Bayesian Multilevel Modeling with the R Package brms.pdf;/Users/claudio/Zotero/storage/5WSVYST8/Bürkner - 2018 - Advanced Bayesian Multilevel Modeling with the R P.pdf}
}

@article{burknerBrmsPackageBayesian2017,
  ids = {buerkner2017a,burknerBrmsPackageBayesian2017a},
  title = {Brms: An {{R}} Package for {{Bayesian}} Multilevel Models Using {{Stan}}},
  shorttitle = {\textbf{Brms}},
  author = {Bürkner, Paul-Christian},
  date = {2017},
  journaltitle = {Journal of Statistical Software},
  volume = {80},
  number = {1},
  pages = {1--28},
  issn = {1548-7660},
  doi = {10.18637/jss.v080.i01},
  url = {http://www.jstatsoft.org/v80/i01/},
  urldate = {2018-09-14},
  abstract = {The brms package implements Bayesian multilevel models in R using the probabilistic programming language Stan. A wide range of distributions and link functions are supported, allowing users to fit – among others – linear, robust linear, binomial, Poisson, survival, response times, ordinal, quantile, zero-inflated, hurdle, and even non-linear models all in a multilevel context. Further modeling options include autocorrelation of the response variable, user defined covariance structures, censored data, as well as metaanalytic standard errors. Prior specifications are flexible and explicitly encourage users to apply prior distributions that actually reflect their beliefs. In addition, model fit can easily be assessed and compared using posterior-predictive checks and leave-one-out crossvalidation. If you use the software, please cite this article as published in the Journal of Statistical Software Bu¨rkner (2017).},
  langid = {english},
  file = {/Users/claudio/MEGA/Zotero/Bürkner_2017_brms.pdf;/Users/claudio/MEGA/Zotero/Bürkner_2017_brms2.pdf;/Users/claudio/Zotero/storage/AK8AZH6Y/Bürkner_2017_brms.pdf;/Users/claudio/Zotero/storage/KLKC94UN/Bürkner_2017_brms2.pdf}
}

@book{cassidyHandbookAttachmentTheory2016,
  ids = {cassidyHandbookAttachmentTheory2016a},
  title = {Handbook of {{Attachment}}: Theory, {{Research}}, and {{Clinical Applications}}},
  author = {Cassidy, Jude and Shaver, Phillip R.},
  date = {2016},
  edition = {Third Edition},
  publisher = {{The Guilford Press}},
  location = {{New York}},
  isbn = {978-1-4625-2529-4},
  langid = {english},
  pagetotal = {1068},
  file = {/Users/claudio/MEGA/Zotero/Cassidy_Shaver_2016_Handbook of Attachment.pdf;/Users/claudio/Zotero/storage/RTY6XD94/Cassidy_Shaver_2016_Handbook of Attachment.pdf}
}

@report{daganConfigurationsMotherChildFatherChild2021,
  type = {preprint},
  title = {Configurations of {{Mother}}-{{Child}} and {{Father}}-{{Child Attachment}} as {{Predictors}} of {{Internalizing}} and {{Externalizing Symptoms}}: An {{Individual Participant Data}} ({{IPD}}) {{Meta}}-{{Analysis}}},
  shorttitle = {Configurations of {{Mother}}-{{Child}} and {{Father}}-{{Child Attachment}} as {{Predictors}} of {{Internalizing}} and {{Externalizing Symptoms}}},
  author = {Dagan, Or and Schuengel, Carlo and Verhage, Marije and van IJzendoorn, Marinus H. and Sagi-Schwartz, Abraham and Madigan, Sheri and Duschinsky, Robbie and Roisman, Glenn I. and Bernard, Kristin and Bakermans-Kranenburg, Marian and Bureau, Jean-Francois and Volling, Brenda and Wong, Maria and Colonnesi, Cristina and Brown, Geoffrey and Eiden, Rina and Fearon, Pasco and Oosterman, Mirjam and Aviezer, Ora and Cummings, E. Mark},
  options = {useprefix=true},
  date = {2021-05-27},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/x4td2},
  url = {https://osf.io/x4td2},
  urldate = {2021-06-07},
  abstract = {An unsettled question in attachment theory and research is the extent to which children’s attachment patterns with mothers and fathers jointly predict developmental outcomes. In this study, we used individual participant data meta-analysis to assess whether early attachment networks with mothers and fathers are associated with children’s internalizing and externalizing symptoms. Following a pre-registered protocol, data from 9 studies and 1,097 children (mean age: 28.67 months) with attachment classifications to both mothers and fathers were included in analyses. We used a linear mixed effects analysis to assess differences in children’s internalizing and externalizing symptoms as assessed via the average of both maternal and paternal reports based on whether children had two, one, or no insecure (or disorganized) attachments. Results indicated that children with an insecure attachment relationship with one or both parents were at higher risk for elevated internalizing symptomatology compared with children who were securely attached to both parents. Children whose attachment relationships with both parents were classified as disorganized had more externalizing symptoms compared to children with either one or no disorganized attachment relationship with their parents. Across attachment classification networks and symptoms, findings suggest (a) a multiplicative effect when children have insecure or disorganized attachment to both parents, and (b) that mother-child and fatherchild attachment relationships may not differ in the roles they play in children’s development of internalizing and externalizing symptoms.},
  langid = {english},
  file = {/Users/claudio/MEGA/Zotero/Dagan et al_2021_Configurations of Mother-Child and Father-Child Attachment as Predictors of.pdf;/Users/claudio/Zotero/storage/MSZD47J9/Dagan et al. - 2021 - Configurations of Mother-Child and Father-Child At.pdf}
}

@online{DemystifyingJacobianAdjustment,
  title = {Demystifying {{Jacobian}} Adjustment for Transformed Parameters in {{Stan}}},
  url = {http://rstudio-pubs-static.s3.amazonaws.com/486816_440106f76c944734a7d4c84761e37388.html},
  urldate = {2021-05-11},
  file = {/Users/claudio/Zotero/storage/KSCM9LRK/486816_440106f76c944734a7d4c84761e37388.html}
}

@article{desantisMethodsDefaultRobust1999,
  title = {Methods for {{Default}} and {{Robust Bayesian Model Comparison}}: The {{Fractional Bayes Factor Approach}}},
  author = {de Santis, Fulvio and Spezzaferri, Fulvio},
  options = {useprefix=true},
  date = {1999},
  journaltitle = {International Statistical Review / Revue Internationale de Statistique},
  volume = {67},
  number = {3},
  eprint = {1403706},
  eprinttype = {jstor},
  pages = {267--286},
  publisher = {{[Wiley, International Statistical Institute (ISI)]}},
  issn = {03067734, 17515823},
  doi = {10.2307/1403706},
  abstract = {In the Bayesian approach to model selection and hypothesis testing, the Bayes factor plays a central role. However, the Bayes factor is very sensitive to prior distributions of parameters. This is a problem especially in the presence of weak prior information on the parameters of the models. The most radical consequence of this fact is that the Bayes factor is undetermined when improper priors are used. Nonetheless, extending the non-informative approach of Bayesian analysis to model selection/testing procedures is important both from a theoretical and an applied viewpoint. The need to develop automatic and robust methods for model comparison has led to the introduction of several alternative Bayes factors. In this paper we review one of these methods: the fractional Bayes factor (O'Hagan, 1995). We discuss general properties of the method, such as consistency and coherence. Furthermore, in addition to the original, essentially asymptotic justifications of the fractional Bayes factor, we provide further finite-sample motivations for its use. Connections and comparisons to other automatic methods are discussed and several issues of robustness with respect to priors and data are considered. Finally, we focus on some open problems in the fractional Bayes factor approach, and outline some possible answers and directions for future research. /// Dans l'approche Bayesienne relative \&\#xe0; la s\&\#xe9;lection d'un model et \&\#xe0; la v\&\#xe9;rification d'une hypoth\&\#xe8;se, le facteur de Bayes joue une r\&\#xf4;le fondamental. Toutefois le facteur de Bayes est tr\&\#xe8;s sensible aux distributions \&\#xe0; priori des param\&\#xe8;tres. Ceci constitue un probl\&\#xe8;me surtout en pr\&\#xe9;sence d'une faible information \&\#xe0; priori en ce qui concerne les param\&\#xe8;tres des models. La cons\&\#xe9;quence la plus radical de ce fait est que le facteur de Bayes est undetermin\&\#xe9; quand les distributions \&\#xe0; priori non informatives sont utilis\&\#xe9;es. Cepandant, il est important d'\&\#xe9;largir l'approche non informative de l'analyse Bayesienne \&\#xe0; l'effet soit de d\&\#xe9;terminer la s\&\#xe9;lection d'un model que de v\&\#xe9;rifier une hypoth\&\#xe8;se. La necessit\&\#xe9; de d\&\#xe9;velopper des m\&\#xe9;thodes automatiques et robustes pour la comparaison des models, a amen\&\#xe9; \&\#xe0; l'introduction des plusieurs facteurs de Bayes alternatifs. Cette \&\#xe9;tude prend en consideration les resultats principaux relatifs \&\#xe0; une de ces methodes, \&\#xe0; savoir le facteur de Bayes fractionnaire. Nous analysons les caracteristique g\&\#xe9;n\&\#xe9;rales de cette methode telles que sa consistance et sa coh\&\#xe9;rence. De plus en sus des justifications asyntotiques donn\&\#xe9;es \&\#xe0; l'origine au facteur fractionnaire de Bayes nous apportons d'autres raisons qui demontrent le bien fond\&\#xe9; de son utilisation dans le domaine d'un \&\#xe9;chantillonage fini. Nous prenons aussi en consideration par comparaison d'autres methodes automatiques et nous examinons d'autres caracteristiques telles que la robustesse par rapport aux les distributions \&\#xe0; priori et aux donn\&\#xe9;es. En conclusion, nous attirons l'attention sur certains probl\&\#xe8;mes non encore resolus et proposons des solutions qui peuvent \&\#xe8;tre explor\&\#xe9;es d'avantage.}
}

@article{dickeyWeightedLikelihoodRatio1971,
  title = {The {{Weighted Likelihood Ratio}}, {{Linear Hypotheses}} on {{Normal Location Parameters}}},
  author = {Dickey, James M.},
  date = {1971-02-01},
  journaltitle = {The Annals of Mathematical Statistics},
  shortjournal = {The Annals of Mathematical Statistics},
  volume = {42},
  number = {1},
  pages = {204--223},
  doi = {10.1214/aoms/1177693507},
  url = {https://doi.org/10.1214/aoms/1177693507},
  file = {/Users/claudio/MEGA/Zotero/Dickey_1971_The Weighted Likelihood Ratio, Linear Hypotheses on Normal Location Parameters.pdf;/Users/claudio/MEGA/Zotero/James M. Dickey_1971_The Weighted Likelihood Ratio, Linear Hypotheses on Normal Location Parameters.pdf}
}

@article{duBayesFactorOnesample2019,
  title = {Bayes Factor in One-Sample Tests of Means with a Sensitivity Analysis: A Discussion of Separate Prior Distributions},
  shorttitle = {Bayes Factor in One-Sample Tests of Means with a Sensitivity Analysis},
  author = {Du, Han and Edwards, Michael C. and Zhang, Zhiyong},
  date = {2019-10},
  journaltitle = {Behavior Research Methods},
  shortjournal = {Behav Res},
  volume = {51},
  number = {5},
  pages = {1998--2021},
  issn = {1554-3528},
  doi = {10.3758/s13428-019-01262-w},
  url = {http://link.springer.com/10.3758/s13428-019-01262-w},
  urldate = {2021-08-09},
  abstract = {Due to some widely known critiques of traditional hypothesis testing, Bayesian hypothesis testing using the Bayes factor has been considered as a better alternative. Previous research about the influence of the prior focuses on the prior for the effect size and there is a debate about how to specify the prior. Thus, the focus of this paper is to explore the impact of different priors on the population mean and variance separately (separate priors) on the Bayes factor, and compare the separate priors with the priors on the effect size. Our simulation results show that both the prior distributions on mean and variance have a considerable influence on the Bayes factor, and different types of priors (different separate priors and priors on the effect size) have different influence patterns. We also find that regardless of separate priors or priors on the effect size, and shapes and centers of the priors, different priors could yield similar Bayes factors. Because noninformative prior distributions bias the Bayes factor in support of the null hypothesis, and very informative priors could be risky, we suggest that researchers use weakly informative priors as reasonable priors and they are expected to provide similar conclusions across different shapes and centers of prior distributions. Conducting sensitivity analysis is helpful in examining the influence of prior distributions and specifying reasonable prior distributions for the Bayes factor. A real data example is used to illustrate how to choose reasonable priors by a sensitivity analysis. We hope our results will help researchers choose prior distributions when conducting Bayesian hypothesis testing.},
  langid = {english},
  file = {/Users/claudio/MEGA/Zotero/Du et al_2019_Bayes factor in one-sample tests of means with a sensitivity analysis.pdf;/Users/claudio/Zotero/storage/KM8S8EQL/Du et al. - 2019 - Bayes factor in one-sample tests of means with a s.pdf}
}

@book{foxCompanionAppliedRegression2019,
  ids = {foxCompanionAppliedRegression2019a},
  title = {An {{R Companion}} to {{Applied Regression}}},
  author = {Fox, John and Weisberg, Sanford},
  date = {2019},
  edition = {Third},
  publisher = {{Sage}},
  location = {{Thousand Oaks CA}},
  url = {https://socialsciences.mcmaster.ca/jfox/Books/Companion/}
}

@article{fraleyItemResponseTheory2000,
  title = {An Item Response Theory Analysis of Self-Report Measures of Adult Attachment.},
  author = {Fraley, R. Chris and Waller, Niels G. and Brennan, Kelly A.},
  date = {2000},
  journaltitle = {Journal of Personality and Social Psychology},
  volume = {78},
  number = {2},
  pages = {350--365},
  publisher = {{American Psychological Association}},
  location = {{US}},
  issn = {1939-1315(Electronic),0022-3514(Print)},
  doi = {10.1037/0022-3514.78.2.350},
  abstract = {Self-report measures of adult attachment are typically scored in ways (e.g., averaging or summing items) that can lead to erroneous inferences about important theoretical issues, such as the degree of continuity in attachment security and the differential stability of insecure attachment patterns. To determine whether existing attachment scales suffer from scaling problems, the authors conducted an item response theory (IRT) analysis of 4 commonly used self-report inventories: Experiences in Close Relationships scales (K. A. Brennan, C. L. Clark, \& P. R. Shaver, 1998), Adult Attachment Scales (N. L. Collins \& S. J. Read, 1990), Relationship Styles Questionnaire (D. W. Griffin \& K. Bartholomew, 1994) and J. Simpson's (1990) attachment scales. Data from 1,085 individuals were analyzed using F. Samejima's (1969) graded response model. The authors' findings indicate that commonly used attachment scales can be improved in a number of important ways. Accordingly, the authors show how IRT techniques can be used to develop new attachment scales with desirable psychometric properties. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {*Attachment Behavior,*Item Analysis (Statistical),*Item Response Theory,*Self-Report,Questionnaires,Rating Scales}
}

@book{gelmanBayesianDataAnalysis2013,
  ids = {gelmanBayesianDataAnalysis2013a},
  title = {Bayesian Data Analysis.},
  author = {Gelman, Andrew and Carlin, J. B. and Stern, H. S. and Dunson, D. B. and Vehtari, A. and Rubin, D. B.},
  date = {2013},
  publisher = {{CRC press}},
  location = {{New York, NY}},
  doi = {10.1201/b16018},
  url = {https://doi.org/10.1201/b16018},
  file = {/Users/claudio/MEGA/Zotero/Gelman et al_2013_Bayesian data analysis.pdf;/Users/claudio/Zotero/storage/HDNWNT67/Gelman et al_2013_Bayesian data analysis.pdf}
}

@online{gelmanBayesianWorkflow2020,
  title = {Bayesian {{Workflow}}},
  author = {Gelman, Andrew and Vehtari, Aki and Simpson, Daniel and Margossian, Charles C. and Carpenter, Bob and Yao, Yuling and Kennedy, Lauren and Gabry, Jonah and Bürkner, Paul-Christian and Modrák, Martin},
  date = {2020-11-03},
  eprint = {2011.01808},
  eprinttype = {arxiv},
  primaryclass = {stat},
  url = {http://arxiv.org/abs/2011.01808},
  urldate = {2021-06-30},
  abstract = {The Bayesian approach to data analysis provides a powerful way to handle uncertainty in all observations, model parameters, and model structure using probability theory. Probabilistic programming languages make it easier to specify and fit Bayesian models, but this still leaves us with many options regarding constructing, evaluating, and using these models, along with many remaining challenges in computation. Using Bayesian inference to solve real-world problems requires not only statistical skills, subject matter knowledge, and programming, but also awareness of the decisions made in the process of data analysis. All of these aspects can be understood as part of a tangled workflow of applied Bayesian statistics. Beyond inference, the workflow also includes iterative model building, model checking, validation and troubleshooting of computational problems, model understanding, and model comparison. We review all these aspects of workflow in the context of several examples, keeping in mind that in practice we will be fitting many models for any given problem, even if only a subset of them will ultimately be relevant for our conclusions.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {/Users/claudio/MEGA/Zotero/Gelman et al_2020_Bayesian Workflow.pdf;/Users/claudio/Zotero/storage/Q7RHX4RJ/Gelman et al_2020_Bayesian Workflow.pdf}
}

@article{gemanStochasticRelaxationGibbs1984,
  title = {Stochastic {{Relaxation}}, {{Gibbs Distributions}}, and the {{Bayesian Restoration}} of {{Images}}},
  author = {Geman, S. and Geman, D.},
  date = {1984-11},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  shortjournal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {PAMI-6},
  number = {6},
  pages = {721--741},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.1984.4767596}
}

@manual{genzMvtnormMultivariateNormal2021,
  type = {manual},
  title = {{{mvtnorm}}: Multivariate Normal and t Distributions},
  author = {Genz, Alan and Bretz, Frank and Miwa, Tetsuhisa and Mi, Xuefei and Leisch, Friedrich and Scheipl, Fabian and Hothorn, Torsten},
  date = {2021},
  url = {https://CRAN.R-project.org/package=mvtnorm}
}

@article{ghosalBayesianInferenceGeneralized2022,
  title = {Bayesian Inference for Generalized Linear Model with Linear Inequality Constraints},
  author = {Ghosal, Rahul},
  date = {2022},
  journaltitle = {Computational Statistics and Data Analysis},
  pages = {17},
  langid = {english},
  keywords = {To read},
  file = {/Users/claudio/Zotero/storage/XTRNKF88/Ghosal - 2022 - Bayesian inference for generalized linear model wi.pdf}
}

@article{ghoshBayesianAnalysisZeroinflated2006,
  title = {Bayesian Analysis of Zero-Inflated Regression Models},
  author = {Ghosh, Sujit K. and Mukhopadhyay, Pabak and Lu, Jye-Chyi(JC)},
  date = {2006-04},
  journaltitle = {Journal of Statistical Planning and Inference},
  shortjournal = {Journal of Statistical Planning and Inference},
  volume = {136},
  number = {4},
  pages = {1360--1375},
  issn = {03783758},
  doi = {10.1016/j.jspi.2004.10.008},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0378375804004008},
  urldate = {2021-06-24},
  abstract = {In modeling defect counts collected from an established manufacturing processes, there are usually a relatively large number of zeros (non-defects). The commonly used models such as Poisson or Geometric distributions can underestimate the zero-defect probability and hence make it difficult to identify significant covariate effects to improve production quality. This article introduces a flexible class of zero inflated models which includes other familiar models such as the Zero Inflated Poisson (ZIP) models, as special cases. A Bayesian estimation method is developed as an alternative to traditionally used maximum likelihood based methods to analyze such data. Simulation studies show that the proposed method has better finite sample performance than the classical method with tighter interval estimates and better coverage probabilities. A real-life data set is analyzed to illustrate the practicability of the proposed method easily implemented using WinBUGS.},
  langid = {english},
  file = {/Users/claudio/MEGA/Zotero/Ghosh et al_2006_Bayesian analysis of zero-inflated regression models.pdf;/Users/claudio/Zotero/storage/GKHC66BJ/Ghosh et al. - 2006 - Bayesian analysis of zero-inflated regression mode.pdf}
}

@article{goodmanExtendedVersionStrengths1999,
  title = {The {{Extended Version}} of the {{Strengths}} and {{Difficulties Questionnaire}} as a {{Guide}} to {{Child Psychiatric Caseness}} and {{Consequent Burden}}},
  author = {Goodman, Robert},
  date = {1999},
  journaltitle = {The Journal of Child Psychology and Psychiatry and Allied Disciplines},
  edition = {1999/07/01},
  volume = {40},
  number = {5},
  pages = {791--799},
  publisher = {{Cambridge University Press}},
  issn = {0021-9630},
  doi = {10.1111/1469-7610.00494},
  url = {https://www.cambridge.org/core/article/extended-version-of-the-strengths-and-difficulties-questionnaire-as-a-guide-to-child-psychiatric-caseness-and-consequent-burden/EA16D19DCF451B04498D0F80E9A82CFD},
  abstract = {The Strengths and Difficulties Questionnaire (SDQ) is a brief behavioural screening  questionnaire that asks about children's and teenagers' symptoms and positive attributes; the extended version also includes an impact supplement that asks if the respondent thinks the young person has a problem, and if so, enquires further about chronicity, distress, social impairment, and burden for others. Closely similar versions are completed by parents, teachers, and young people aged 11 or more. The validation study involved two groups of 5–15-year-olds: a community sample (N=467) and a psychiatric clinic sample (N=232). The two groups had markedly different distributions on the measures of perceived difficulties, impact (distress plus social impairment), and burden. Impact scores were better than symptom scores at discriminating between the community and clinic samples; discrimination based on the single “Is there a problem?” item was almost as good. The SDQ burden rating correlated well (r=.74) with a standardised interview rating of burden. For clinicians and researchers with an interest in psychiatric caseness and the determinants of service use, the impact supplement of the extended SDQ appears to provide useful additional information without taking up much more of respondents' time.},
  keywords = {Behaviour problems,burden,child psychiatric disorder,impact,questionnaires,screening},
  file = {/Users/claudio/MEGA/Zotero/Goodman_1999_The Extended Version of the Strengths and Difficulties Questionnaire as a.pdf}
}

@article{goodmanWhenUseBroader2010,
  ids = {goodmanWhenUseBroader2010a},
  title = {When to {{Use Broader Internalising}} and {{Externalising Subscales Instead}} of the {{Hypothesised Five Subscales}} on the {{Strengths}} and {{Difficulties Questionnaire}} ({{SDQ}}): Data from {{British Parents}}, {{Teachers}} and {{Children}}},
  shorttitle = {When to {{Use Broader Internalising}} and {{Externalising Subscales Instead}} of the {{Hypothesised Five Subscales}} on the {{Strengths}} and {{Difficulties Questionnaire}} ({{SDQ}})},
  author = {Goodman, Anna and Lamping, Donna L. and Ploubidis, George B.},
  date = {2010-11-01},
  journaltitle = {Journal of Abnormal Child Psychology},
  shortjournal = {J Abnorm Child Psychol},
  volume = {38},
  number = {8},
  pages = {1179--1191},
  publisher = {{Springer}},
  location = {{Germany}},
  issn = {1573-2835},
  doi = {10.1007/s10802-010-9434-x},
  url = {https://doi.org/10.1007/s10802-010-9434-x},
  urldate = {2019-01-06},
  abstract = {The Strengths and Difficulties Questionnaire (SDQ) is a widely used child mental health questionnaire with five hypothesised subscales. There is theoretical and preliminary empirical support for combining the SDQ’s hypothesised emotional and peer subscales into an ‘internalizing’ subscale and the hypothesised behavioral and hyperactivity subscales into an ‘externalizing’ subscale (alongside the fifth prosocial subscale). We examine this using parent, teacher and youth SDQ data from a representative sample of 5–16 year olds in Britain (N = 18,222). Factor analyses generally supported second-order internalizing and externalizing factors, and the internalizing and externalizing subscales showed good convergent and discriminant validity across informants and with respect to clinical disorder. By contrast, discriminant validity was poorer between the emotional and peer subscales and between the behavioral, hyperactivity and prosocial subscales. This applied particularly to children with low scores on those subscales. We conclude that there are advantages to using the broader internalizing and externalizing SDQ subscales for analyses in low-risk samples, while retaining all five subscales when screening for disorder.},
  langid = {english},
  keywords = {*Childhood Development,*Externalization,*Internalization,*Mental Health,*Psychometrics,Britain,Construct validity,Externalizing problems,Factor structure,Internalizing problems,Parents,Strengths and Difficulties Questionnaire,Teachers,Test Reliability,Test Validity},
  file = {/Users/claudio/MEGA/Zotero/Goodman et al_2010_When to Use Broader Internalising and Externalising Subscales Instead of the.pdf}
}

@online{gronauBridgesamplingPackageEstimating2018,
  title = {Bridgesampling: An {{R Package}} for {{Estimating Normalizing Constants}}},
  shorttitle = {Bridgesampling},
  author = {Gronau, Quentin F. and Singmann, Henrik and Wagenmakers, Eric-Jan},
  date = {2018-09-18},
  eprint = {1710.08162},
  eprinttype = {arxiv},
  primaryclass = {stat},
  url = {http://arxiv.org/abs/1710.08162},
  urldate = {2021-05-27},
  abstract = {Statistical procedures such as Bayes factor model selection and Bayesian model averaging require the computation of normalizing constants (e.g., marginal likelihoods). These normalizing constants are notoriously difficult to obtain, as they usually involve highdimensional integrals that cannot be solved analytically. Here we introduce an R package that uses bridge sampling (Meng and Wong 1996; Meng and Schilling 2002) to estimate normalizing constants in a generic and easy-to-use fashion. For models implemented in Stan, the estimation procedure is automatic. We illustrate the functionality of the package with three examples.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Computation},
  file = {/Users/claudio/MEGA/Zotero/Gronau et al_2018_Bridgesampling.pdf;/Users/claudio/Zotero/storage/8JED3CYZ/Gronau et al. - 2018 - bridgesampling An R Package for Estimating Normal.pdf}
}

@article{gronauTutorialBridgeSampling2017,
  title = {A Tutorial on Bridge Sampling},
  author = {Gronau, Quentin F. and Sarafoglou, Alexandra and Matzke, Dora and Ly, Alexander and Boehm, Udo and Marsman, Maarten and Leslie, David S. and Forster, Jonathan J. and Wagenmakers, Eric-Jan and Steingroever, Helen},
  date = {2017-12},
  journaltitle = {Journal of Mathematical Psychology},
  shortjournal = {Journal of Mathematical Psychology},
  volume = {81},
  pages = {80--97},
  issn = {00222496},
  doi = {10.1016/j.jmp.2017.09.005},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0022249617300640},
  urldate = {2021-05-27},
  abstract = {The marginal likelihood plays an important role in many areas of Bayesian statistics such as parameter estimation, model comparison, and model averaging. In most applications, however, the marginal likelihood is not analytically tractable and must be approximated using numerical methods. Here we provide a tutorial on bridge sampling (Bennett, 1976; Meng \& Wong, 1996), a reliable and relatively straightforward sampling method that allows researchers to obtain the marginal likelihood for models of varying complexity. First, we introduce bridge sampling and three related sampling methods using the beta-binomial model as a running example. We then apply bridge sampling to estimate the marginal likelihood for the Expectancy Valence (EV) model—a popular model for reinforcement learning. Our results indicate that bridge sampling provides accurate estimates for both a single participant and a hierarchical version of the EV model. We conclude that bridge sampling is an attractive method for mathematical psychologists who typically aim to approximate the marginal likelihood for a limited set of possibly high-dimensional models.},
  langid = {english},
  file = {/Users/claudio/MEGA/Zotero/Gronau et al_2017_A tutorial on bridge sampling.pdf;/Users/claudio/Zotero/storage/ZREL5TQV/Gronau et al. - 2017 - A tutorial on bridge sampling.pdf}
}

@article{guApproximatedAdjustedFractional2018,
  title = {Approximated Adjusted Fractional {{Bayes}} Factors: A General Method for Testing Informative Hypotheses},
  shorttitle = {Approximated Adjusted Fractional {{Bayes}} Factors},
  author = {Gu, Xin and Mulder, Joris and Hoijtink, Herbert},
  date = {2018-05},
  journaltitle = {British Journal of Mathematical and Statistical Psychology},
  shortjournal = {Br J Math Stat Psychol},
  volume = {71},
  number = {2},
  pages = {229--261},
  issn = {00071102},
  doi = {10.1111/bmsp.12110},
  url = {http://doi.wiley.com/10.1111/bmsp.12110},
  urldate = {2021-05-13},
  langid = {english},
  keywords = {Letto},
  file = {/Users/claudio/MEGA/Zotero/Gu et al_2018_Approximated adjusted fractional Bayes factors.pdf;/Users/claudio/Zotero/storage/X623DBMS/Gu et al. - 2018 - Approximated adjusted fractional Bayes factors A .pdf}
}

@article{guBayesianEvaluationInequality2014,
  title = {Bayesian Evaluation of Inequality Constrained Hypotheses.},
  author = {Gu, Xin and Mulder, Joris and Deković, Maja and Hoijtink, Herbert},
  date = {2014},
  journaltitle = {Psychological Methods},
  shortjournal = {Psychological Methods},
  volume = {19},
  number = {4},
  pages = {511--527},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000017},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/met0000017},
  urldate = {2021-05-13},
  abstract = {Bayesian evaluation of inequality constrained hypotheses enables researchers to investigate their expectations with respect to the structure among model parameters. This article proposes an approximate Bayes procedure that can be used for the selection of the best of a set of inequality constrained hypotheses based on the Bayes factor in a very general class of statistical models. The software package BIG is provided such that psychologists can use the approach proposed for the analysis of their own data. To illustrate the approximate Bayes procedure and the use of BIG, we evaluate inequality constrained hypotheses in a path model and a logistic regression model. Two simulation studies on the performance of our approximate Bayes procedure show that it results in accurate Bayes factors.},
  langid = {english},
  keywords = {Letto},
  file = {/Users/claudio/MEGA/Zotero/Gu et al_2014_Bayesian evaluation of inequality constrained hypotheses.pdf;/Users/claudio/Zotero/storage/PUHJAVZD/Gu et al. - 2014 - Bayesian evaluation of inequality constrained hypo.pdf}
}

@article{guestHowComputationalModeling,
  title = {How {{Computational Modeling Can Force Theory Building}} in {{Psychological Science}}},
  author = {Guest, Olivia and Martin, Andrea E},
  pages = {14},
  abstract = {Psychology endeavors to develop theories of human capacities and behaviors on the basis of a variety of methodologies and dependent measures. We argue that one of the most divisive factors in psychological science is whether researchers choose to use computational modeling of theories (over and above data) during the scientific-inference process. Modeling is undervalued yet holds promise for advancing psychological science. The inherent demands of computational modeling guide us toward better science by forcing us to conceptually analyze, specify, and formalize intuitions that otherwise remain unexamined—what we dub open theory. Constraining our inference process through modeling enables us to build explanatory and predictive theories. Here, we present scientific inference in psychology as a path function in which each step shapes the next. Computational modeling can constrain these steps, thus advancing scientific inference over and above the stewardship of experimental practice (e.g., preregistration). If psychology continues to eschew computational modeling, we predict more replicability crises and persistent failure at coherent theory building. This is because without formal modeling we lack open and transparent theorizing. We also explain how to formalize, specify, and implement a computational model, emphasizing that the advantages of modeling can be achieved by anyone with benefit to all.},
  langid = {english},
  file = {/Users/claudio/MEGA/Zotero/Guest_Martin_How Computational Modeling Can Force Theory Building in Psychological Science.pdf;/Users/claudio/Zotero/storage/STW8V5BU/Guest and Martin - How Computational Modeling Can Force Theory Buildi.pdf}
}

@article{hastingsMonteCarloSampling1970,
  title = {Monte {{Carlo}} Sampling Methods Using {{Markov}} Chains and Their Applications},
  author = {Hastings, W. K.},
  date = {1970-04-01},
  journaltitle = {Biometrika},
  shortjournal = {Biometrika},
  volume = {57},
  number = {1},
  pages = {97--109},
  issn = {0006-3444},
  doi = {10.1093/biomet/57.1.97},
  url = {https://doi.org/10.1093/biomet/57.1.97},
  urldate = {2021-08-10},
  abstract = {A generalization of the sampling method introduced by Metropolis et al. (1953) is presented along with an exposition of the relevant theory, techniques of application and methods and difficulties of assessing the error in Monte Carlo estimates. Examples of the methods, including the generation of random orthogonal matrices and potential applications of the methods to numerical problems arising in statistics, are discussed.}
}

@article{heckMultinomialModelsLinear2019,
  title = {Multinomial Models with Linear Inequality Constraints: Overview and Improvements of Computational Methods for {{Bayesian}} Inference},
  shorttitle = {Multinomial Models with Linear Inequality Constraints},
  author = {Heck, Daniel W. and Davis-Stober, Clintin P.},
  date = {2019-08},
  journaltitle = {Journal of Mathematical Psychology},
  shortjournal = {Journal of Mathematical Psychology},
  volume = {91},
  pages = {70--87},
  issn = {00222496},
  doi = {10.1016/j.jmp.2019.03.004},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0022249618301457},
  urldate = {2021-05-11},
  abstract = {Many psychological theories can be operationalized as linear inequality constraints on the parameters of multinomial distributions (e.g., discrete choice analysis). These constraints can be described in two equivalent ways: Either as the solution set to a system of linear inequalities or as the convex hull of a set of extremal points (vertices). For both representations, we describe a general Gibbs sampler for drawing posterior samples in order to carry out Bayesian analyses. We also summarize alternative sampling methods for estimating Bayes factors for these model representations using the encompassing Bayes factor method. We introduce the R package multinomineq, which provides an easily-accessible interface to a computationally efficient implementation of these techniques.},
  langid = {english},
  keywords = {To read},
  file = {/Users/claudio/MEGA/Zotero/Heck_Davis-Stober_2019_Multinomial models with linear inequality constraints.pdf;/Users/claudio/Zotero/storage/GMWDVEQM/Heck_Davis-Stober_2019_Multinomial models with linear inequality constraints.pdf}
}

@report{heckReviewApplicationsBayes2020,
  type = {preprint},
  title = {A {{Review}} of {{Applications}} of the {{Bayes Factor}} in {{Psychological Research}}},
  author = {Heck, Daniel W. and Boehm, Udo and Böing-Messing, Florian and Bürkner, Paul - Christian and Derks, Koen and Dienes, Zoltan and Fu, Qianrao and Gu, Xin and Karimova, Diana and Kiers, Henk and Klugkist, Irene and Kuiper, Rebecca M. and Lee, Michael David and Leenders, Roger and Leplaa, Hidde Jelmer and Linde, Maximilian and Ly, Alexander and Meijerink-Bosman, Marlyne and Moerbeek, Mirjam and Mulder, Joris and Palfi, Bence and Schönbrodt, Felix D. and Tendeiro, Jorge and van den Bergh, Don and Van Lissa, Caspar J. and van Ravenzwaaij, Don and {vanpaemel}, wolf and Wagenmakers, Eric-Jan and Williams, Donald Ray and Zondervan-Zwijnenburg, Marielle and Hoijtink, Herbert},
  options = {useprefix=true},
  date = {2020-10-20},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/cu43g},
  url = {https://osf.io/cu43g},
  urldate = {2021-05-31},
  abstract = {The last 25 years have shown a steady increase in attention for the Bayes factor as a tool for hypothesis evaluation and model selection. The present review highlights the potential of the Bayes factor in psychological research. We discuss six types of applications: Bayesian evaluation of point null, interval, and informative hypotheses, Bayesian evidence synthesis, Bayesian variable selection and model averaging, and Bayesian evaluation of cognitive models. We elaborate what each application entails, give illustrative examples, and provide an overview of key references and software with links to other applications. The paper is concluded with a discussion of the opportunities and pitfalls of Bayes factor applications and a sketch of corresponding future research lines.},
  langid = {english},
  file = {/Users/claudio/MEGA/Zotero/Heck et al_2020_A Review of Applications of the Bayes Factor in Psychological Research.pdf;/Users/claudio/Zotero/storage/FTL4BS3W/Heck et al. - 2020 - A Review of Applications of the Bayes Factor in Ps.pdf}
}

@book{hoijtinkInformativeHypothesesTheory2012,
  title = {Informative Hypotheses: Theory and Practice for Behavioral and Social Scientists},
  author = {Hoijtink, Herbert},
  date = {2012},
  publisher = {{Chapman and Hall/CRC}},
  location = {{Boca Raton, FL}},
  doi = {10.1201/b11158},
  url = {https://www.taylorfrancis.com/books/9781439880524},
  urldate = {2021-05-31},
  isbn = {978-1-4398-8052-4},
  langid = {english},
  file = {/Users/claudio/MEGA/Zotero/Hoijtink_2012_Informative hypotheses.pdf;/Users/claudio/Zotero/storage/VQ4YJNCD/Hoijtink - 2011 - Informative Hypotheses.pdf}
}

@article{hoijtinkTutorialTestingHypotheses2019,
  title = {A Tutorial on Testing Hypotheses Using the {{Bayes}} Factor.},
  author = {Hoijtink, Herbert and Mulder, Joris and van Lissa, Caspar and Gu, Xin},
  options = {useprefix=true},
  date = {2019-10},
  journaltitle = {Psychological Methods},
  shortjournal = {Psychological Methods},
  volume = {24},
  number = {5},
  pages = {539--556},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000201},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/met0000201},
  urldate = {2021-05-13},
  abstract = {Learning about hypothesis evaluation using the Bayes factor could enhance psychological research. In contrast to null-hypothesis significance testing: it renders the evidence in favor of each of the hypotheses under consideration (it can be used to quantify support for the null-hypothesis) instead of a dichotomous reject/do-not-reject decision; it can straightforwardly be used for the evaluation of multiple hypotheses without having to bother about the proper manner to account for multiple testing; and, it allows continuous re-evaluation of hypotheses after additional data have been collected (Bayesian updating). This tutorial addresses researchers considering to evaluate their hypotheses by means of the Bayes factor. The focus is completely applied and each topic discussed is illustrated using Bayes factors for the evaluation of hypotheses in the context of an ANOVA model, obtained using the R package bain. Readers can execute all the analyses presented while reading this tutorial if they download bain and the R-codes used. It will be elaborated in a completely non-technical manner: what the Bayes factor is, how it can be obtained, how Bayes factors should be interpreted, and what can be done with Bayes factors. After reading this tutorial and executing the associated code, researchers will be able to use their own data for the evaluation of hypotheses by means of the Bayes factor, not only in the context of ANOVA models, but also in the context of other statistical models.},
  langid = {english},
  file = {/Users/claudio/MEGA/Zotero/Hoijtink et al_2019_A tutorial on testing hypotheses using the Bayes factor.pdf;/Users/claudio/Zotero/storage/UH74J8BX/Hoijtink et al. - 2019 - A tutorial on testing hypotheses using the Bayes f.pdf}
}

@book{jeffreysTheoryProbability1961,
  title = {Theory of Probability},
  author = {Jeffreys, H.},
  date = {1961},
  edition = {3rd Edition},
  publisher = {{Oxford University Press.}},
  location = {{New York}}
}

@article{katoBayesianApproachInequality2006,
  ids = {katoBayesianApproachInequality2006a},
  title = {A {{Bayesian}} Approach to Inequality Constrained Linear Mixed Models: Estimation and Model Selection},
  shorttitle = {A {{Bayesian}} Approach to Inequality Constrained Linear Mixed Models},
  author = {Kato, Bernet S and Hoijtink, Herbert},
  date = {2006-10},
  journaltitle = {Statistical Modelling},
  shortjournal = {Statistical Modelling},
  volume = {6},
  number = {3},
  pages = {231--249},
  issn = {1471-082X, 1477-0342},
  doi = {10.1191/1471082X06st119oa},
  url = {http://journals.sagepub.com/doi/10.1191/1471082X06st119oa},
  urldate = {2021-05-11},
  abstract = {Constrained parameter problems arise in a wide variety of applications. This article deals with estimation and model selection in linear mixed models with inequality constraints on the parameters. It is shown that different theories can be translated into statistical models by putting constraints on the model parameters yielding a set of competing models. A new approach based on the principle of encompassing priors is proposed and used to compute Bayes factors and subsequently posterior model probabilities. Model selection is based on posterior model probabilities. The approach is illustrated using a longitudinal data set.},
  langid = {english},
  keywords = {Letto},
  file = {/Users/claudio/MEGA/Zotero/Kato_Hoijtink_2006_A Bayesian approach to inequality constrained linear mixed models.pdf;/Users/claudio/Zotero/storage/8VQFY7GA/Kato_Hoijtink_2006_A Bayesian approach to inequality constrained linear mixed models.pdf}
}

@article{kernsAttachmentMiddleChildhood2005,
  title = {Attachment in Middle Childhood.},
  editor = {Kerns, Kathryn A. and Richardson, Rhonda A.},
  date = {2005},
  journaltitle = {Attachment in middle childhood.},
  pages = {xiv, 289-xiv, 289},
  publisher = {{The Guilford Press}},
  location = {{New York,  NY,  US}},
  issn = {1-59385-121-9 (Hardcover)},
  abstract = {A growing body of research has established that individuals who form secure attachments in early childhood or adolescence experience better social adjustment and mental health outcomes. Yet the important years between ages 6 and 12 have been relatively neglected in the literature. This volume is the first to bring together emerging theories and findings on attachment in middle childhood, including the results of key longitudinal studies. With contributions from leading investigators, the book explores the effects on attachment of a wide range of factors in middle childhood, including children's broadening network of social relationships. Data are presented on whether the quality of attachment in middle childhood can be predicted by assessments earlier in life, and what may explain changes over time. Chapters examine the implications of attachment for children's social and emotional functioning, their academic development, and the later emergence of adolescent problems. Also considered are challenges in conceptualizing and assessing attachment during this period, and the strengths and limitations of existing measurement approaches. The concluding chapter offers a thought-provoking commentary on the volume's major themes, identifying areas of scientific progress and highlighting questions and problems that still need to be addressed. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  keywords = {*Attachment Behavior,*Childhood Development,*Social Adjustment,*Theories,Measurement}
}

@article{kuhaAICBICComparisons2004,
  title = {{{AIC}} and {{BIC}}: Comparisons of {{Assumptions}} and {{Performance}}},
  shorttitle = {{{AIC}} and {{BIC}}},
  author = {Kuha, Jouni},
  date = {2004},
  journaltitle = {Sociological Methods \& Research},
  volume = {33},
  number = {2},
  pages = {188--229},
  issn = {0049-1241, 1552-8294},
  doi = {10.1177/0049124103262065},
  url = {http://journals.sagepub.com/doi/10.1177/0049124103262065},
  langid = {english},
  file = {/Users/claudio/MEGA/Zotero/Kuha_2004_AIC and BIC.pdf}
}

@book{lindleyBayesianStatisticsReview1972,
  title = {Bayesian Statistics, a Review},
  author = {Lindley, D. V.},
  date = {1972},
  publisher = {{PA: SIAM.}},
  location = {{Philadelphia}}
}

@article{lindleyStatisticalParadox1957,
  title = {A {{Statistical Paradox}}},
  author = {Lindley, D. V.},
  date = {1957-06-01},
  journaltitle = {Biometrika},
  shortjournal = {Biometrika},
  volume = {44},
  number = {1-2},
  pages = {187--192},
  issn = {0006-3444},
  doi = {10.1093/biomet/44.1-2.187},
  url = {https://doi.org/10.1093/biomet/44.1-2.187},
  urldate = {2021-08-05}
}

@article{liuBAYESIANINFERENCEZEROINFLATED,
  title = {{{BAYESIAN INFERENCE FOR ZERO}}-{{INFLATED POISSON REGRESSION MODELS}}},
  author = {Liu, Hui and Powers, Daniel A},
  pages = {34},
  abstract = {Count data with excess zeros are common in social science research and can be considered as a special case of mixture structured data. We exploit the flexibility of the Bayesian analytic approach to model the mixture data structure inherent in zero-inflated count data by using the zero-inflated Poisson (ZIP) model. We discuss the importance of modelling excess-zero count data in social sciences and review the distributional properties of zero-inflated count data, with special attention given to its mixture data structure in the context of Bayesian modelling. We illustrate the methodology using data from the Americans’ changing lives (ACL) survey on cigarette smoking. Results from predictive checks suggest that the proposed Bayesian ZIP model provides a good fit to the 2010 Mathematics Subject Classification: 62F15, 62J12.},
  langid = {english},
  keywords = {To read},
  file = {/Users/claudio/MEGA/Zotero/Liu_Powers_BAYESIAN INFERENCE FOR ZERO-INFLATED POISSON REGRESSION MODELS.pdf;/Users/claudio/Zotero/storage/IJ9BAQ6U/Liu and Powers - BAYESIAN INFERENCE FOR ZERO-INFLATED POISSON REGRE.pdf}
}

@article{liuZeroandoneinflatedPoissonRegression2021,
  title = {Zero-and-One-Inflated {{Poisson}} Regression Model},
  author = {Liu, Wenchen and Tang, Yincai and Xu, Ancha},
  date = {2021-04},
  journaltitle = {Statistical Papers},
  shortjournal = {Stat Papers},
  volume = {62},
  number = {2},
  pages = {915--934},
  issn = {0932-5026, 1613-9798},
  doi = {10.1007/s00362-019-01118-7},
  url = {http://link.springer.com/10.1007/s00362-019-01118-7},
  urldate = {2021-06-24},
  abstract = {In this paper, a zero-and-one-inflated Poisson (ZOIP) regression model is proposed. The maximum likelihood estimation (MLE) and Bayesian estimation for this model are investigated. Three estimation methods of the ZOIP regression model are obtained based on data augmentation method which is expectation-maximization (EM) algorithm, generalized expectation-maximization (GEM) algorithm and Gibbs sampling respectively. A simulation study is conducted to assess the performance of the proposed estimation for various sample sizes. Finally, an accidental deaths data set is analyzed to illustrate the practicability of the proposed method.},
  langid = {english},
  file = {/Users/claudio/MEGA/Zotero/Liu et al_2021_Zero-and-one-inflated Poisson regression model.pdf;/Users/claudio/Zotero/storage/QFQFYRN8/Liu et al. - 2021 - Zero-and-one-inflated Poisson regression model.pdf}
}

@article{ludeckePerformancePackageAssessment2021,
  title = {{{performance}}: An {{R}} Package for Assessment, Comparison and Testing of Statistical Models},
  author = {Lüdecke, Daniel and Ben-Shachar, Mattan S. and Patil, Indrajeet and Waggoner, Philip and Makowski, Dominique},
  date = {2021},
  journaltitle = {Journal of Open Source Software},
  volume = {6},
  number = {60},
  pages = {3139},
  doi = {10.21105/joss.03139}
}

@article{marciBriefExperiencesClose2019,
  title = {The Brief {{Experiences}} in {{Close Relationships Scale}} - {{Revised Child}} Version ({{ECR}}-{{RC}}): Factor Structure and Invariance across Middle Childhood and Early Adolescence},
  author = {Marci, Tatiana and Moscardino, Ughetta and Altoè, Gianmarco},
  date = {2019},
  journaltitle = {International Journal of Behavioral Development},
  volume = {43},
  number = {5},
  eprint = {https://doi.org/10.1177/0165025418785975},
  pages = {409--423},
  doi = {10.1177/0165025418785975},
  url = {https://doi.org/10.1177/0165025418785975},
  abstract = {The recently developed short form of the Experiences in Close Relationships Scale-Revised Child version (ECR-RC) is a promising tool to assess anxious and avoidant attachment in children and adolescents. Yet, evidence concerning its validity in middle childhood is limited. This study aimed to test the psychometric properties of the 12-item ECR-RC for both mother and father forms in a sample of 448 Italian children (50.2\% girls) aged between 8 and 13 years. The scale was adapted by changing the response format to make it more understandable for young children. Psychometric proprieties of the brief ECR-RC were investigated by testing its factor structure and internal consistency, invariance across middle childhood and early adolescence, and concurrent and convergent validity. A series of confirmatory factor analyses provided support for the two-factor structure (i.e., anxiety and avoidance) of the ECR-RC, and multi-group confirmatory factor analyses supported its invariance across middle childhood and early adolescence. Older children reported significantly higher latent mean values in avoidant attachment to both parents compared to their younger counterparts. Furthermore, the questionnaire showed evidence of concurrent and convergent validity. Our results indicate that the 12-item version of the ECR-RC is a psychometrically robust instrument to assess avoidance and anxiety toward mother and father among Italian children and early adolescents.}
}

@book{mcelreathStatisticalRethinkingBayesian2020,
  ids = {mcelreathStatisticalRethinkingBayesian2020a},
  title = {Statistical Rethinking: A {{Bayesian}} Course with Examples in {{R}} and {{Stan}}},
  shorttitle = {Statistical Rethinking},
  author = {McElreath, Richard},
  date = {2020},
  series = {{{CRC}} Texts in Statistical Science},
  edition = {2},
  publisher = {{Taylor and Francis, CRC Press}},
  location = {{Boca Raton}},
  abstract = {"Statistical Rethinking: A Bayesian Course with Examples in R and Stan, Second Edition builds knowledge/confidence in statistical modeling. Pushes readers to perform step-by-step calculations (usually automated.) Unique, computational approach ensures readers understand details to make reasonable choices and interpretations in their modeling work"--},
  isbn = {978-0-367-13991-9},
  langid = {english},
  file = {/Users/claudio/MEGA/Zotero/McElreath_2020_Statistical rethinking.pdf;/Users/claudio/Zotero/storage/3JYGDIW6/McElreath_2020_Statistical rethinking.pdf}
}

@book{mikulincerAttachmentAdulthoodStructure2007,
  title = {Attachment in Adulthood: Structure, Dynamics, and Change.},
  author = {Mikulincer, Mario and Shaver, Phillip R.},
  date = {2007},
  series = {Attachment in Adulthood: Structure, Dynamics, and Change.},
  pages = {578},
  publisher = {{The Guilford Press}},
  location = {{New York,  NY,  US}},
  abstract = {The volume reviews the foundations of attachment theory and traces how the study of adolescents and adults has enriched Bowlby and Ainsworth's original ideas. Measures of attachment style and related constructs (several of which are reprinted in the appendices) are described in depth, and their contributions to understanding both normative processes and individual differences are explored. The authors analyze findings from thousands of studies to show how attachment has been used to further scientific knowledge about nearly all aspects of social functioning. Revealed are compelling insights into the processes underlying mental representations of self and others, personal goals and strivings, healthy and unhealthy coping strategies, couple dynamics, sexuality, caregiving, psychopathology, psychotherapy, and organizational behavior. The concluding chapter reflects on the key issues addressed, considers the deeper philosophical implications of current work in the field, and identifies pivotal directions for future investigation. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  isbn = {1-59385-457-9 (Hardcover); 978-1-59385-457-7 (Hardcover)},
  pagetotal = {578},
  keywords = {*Attachment Behavior,Social Functioning}
}

@article{moreyPhilosophyBayesFactors2016,
  title = {The Philosophy of {{Bayes}} Factors and the Quantification of Statistical Evidence},
  author = {Morey, Richard D. and Romeijn, Jan-Willem and Rouder, Jeffrey N.},
  date = {2016-06},
  journaltitle = {Journal of Mathematical Psychology},
  shortjournal = {Journal of Mathematical Psychology},
  volume = {72},
  pages = {6--18},
  issn = {00222496},
  doi = {10.1016/j.jmp.2015.11.001},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0022249615000723},
  urldate = {2021-05-13},
  abstract = {A core aspect of science is using data to assess the degree to which data provide evidence for competing claims, hypotheses, or theories. Evidence is by definition something that should change the credibility of a claim in a reasonable person’s mind. However, common statistics, such as significance testing and confidence intervals have no interface with concepts of belief, and thus it is unclear how they relate to statistical evidence. We explore the concept of statistical evidence, and how it can be quantified using the Bayes factor. We also discuss the philosophical issues inherent in the use of the Bayes factor.},
  langid = {english},
  file = {/Users/claudio/MEGA/Zotero/Morey et al_2016_The philosophy of Bayes factors and the quantification of statistical evidence.pdf;/Users/claudio/Zotero/storage/35H3EWNI/Morey et al. - 2016 - The philosophy of Bayes factors and the quantifica.pdf}
}

@article{mulderBayesFactorsTesting2016,
  title = {Bayes Factors for Testing Order-Constrained Hypotheses on Correlations},
  author = {Mulder, Joris},
  date = {2016-06},
  journaltitle = {Journal of Mathematical Psychology},
  shortjournal = {Journal of Mathematical Psychology},
  volume = {72},
  pages = {104--115},
  issn = {00222496},
  doi = {10.1016/j.jmp.2014.09.004},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0022249614000601},
  urldate = {2021-05-13},
  abstract = {Correlation coefficients play a key role in the social and behavioral sciences for quantifying the degree of linear association between variables. A Bayes factor is proposed that allows researchers to test hypotheses with order constraints on correlation coefficients in a direct manner. This Bayes factor balances between fit and complexity of order-constrained hypotheses in a natural way. A diffuse prior on the correlation matrix is used that minimizes prior shrinkage and results in most evidence for an order-constrained hypothesis that is supported by the data. An efficient method is proposed for the computation of the Bayes factor. A key aspect in the computation is a Fisher Z transformation on the posterior distribution of the correlations such that an approximately normal distribution is obtained. The methodology is implemented in a freely downloadable software program called ‘‘BOCOR’’. The methods are applied to a multitrait–multimethod analysis, a repeated measures study, and a study on directed moderator effects. © 2014 Elsevier Inc. All rights reserved.},
  langid = {english},
  keywords = {Letto Parzialmente},
  file = {/Users/claudio/MEGA/Zotero/Mulder_2016_Bayes factors for testing order-constrained hypotheses on correlations.pdf;/Users/claudio/Zotero/storage/PYUHF2IL/Mulder - 2016 - Bayes factors for testing order-constrained hypoth.pdf}
}

@online{mulderBayesFactorTesting2019,
  title = {Bayes Factor Testing of Equality and Order Constraints on Measures of Association in Social Research},
  author = {Mulder, Joris and Gelissen, John P. T. M.},
  date = {2019-04-03},
  eprint = {1807.05819},
  eprinttype = {arxiv},
  primaryclass = {stat},
  url = {http://arxiv.org/abs/1807.05819},
  urldate = {2021-05-11},
  abstract = {Measures of association play a central role in the social sciences to quantify the strength of a linear relationship between the variables of interest. In many applications researchers can translate scientific expectations to hypotheses with equality and/or order constraints on these measures of association. In this paper a Bayes factor test is proposed for testing multiple hypotheses with constraints on the measures of association between ordinal and/or continuous variables, possibly after correcting for certain covariates. This test can be used to obtain a direct answer to the research question how much evidence there is in the data for a social science theory relative to competing theories. The accompanying software package ‘BCT’ allows users to apply the methodology in an easy manner. An empirical application from leisure studies about the associations between life, leisure and relationship satisfaction and an application about the differences about egalitarian justice beliefs across countries are used to illustrate the methodology.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Letto Parzialmente,Statistics - Methodology},
  file = {/Users/claudio/MEGA/Zotero/Mulder_Gelissen_2019_Bayes factor testing of equality and order constraints on measures of.pdf;/Users/claudio/Zotero/storage/D2X73UGU/Mulder and Gelissen - 2019 - Bayes factor testing of equality and order constra.pdf}
}

@article{mulderBIEMSFortran902012,
  title = {{{BIEMS}} : A {{Fortran}} 90 {{Program}} for {{Calculating Bayes Factors}} for {{Inequality}} and {{Equality Constrained Models}}},
  shorttitle = {{{BIEMS}}},
  author = {Mulder, Joris and Hoijtink, Herbert and de Leeuw, Christiaan},
  date = {2012},
  journaltitle = {Journal of Statistical Software},
  shortjournal = {J. Stat. Soft.},
  volume = {46},
  number = {2},
  issn = {1548-7660},
  doi = {10.18637/jss.v046.i02},
  url = {http://www.jstatsoft.org/v46/i02/},
  urldate = {2021-08-11},
  abstract = {This paper discusses a Fortran 90 program referred to as BIEMS (Bayesian inequality and equality constrained model selection) that can be used for calculating Bayes factors of multivariate normal linear models with equality and/or inequality constraints between the model parameters versus a model containing no constraints, which is referred to as the unconstrained model. The prior that is used under the unconstrained model is the conjugate expected-constrained posterior prior and the prior under the constrained model is proportional to the unconstrained prior truncated in the constrained space. This results in Bayes factors that appropriately balance between model fit and complexity for a broad class of constrained models. When the set of equality and/or inequality constraints in the model represents a hypothesis that applied researchers have in, for instance, (M)AN(C)OVA, (multivariate) regression, or repeated measurements, the obtained Bayes factor can be used to determine how much evidence is provided by the data in favor of the hypothesis in comparison to the unconstrained model. If several hypotheses are under investigation, the Bayes factors between the constrained models can be calculated using the obtained Bayes factors from BIEMS. Furthermore, posterior model probabilities of constrained models are provided which allows the user to compare the models directly with each other.},
  langid = {english},
  file = {/Users/claudio/MEGA/Zotero/Mulder et al_2012_BIEMS.pdf;/Users/claudio/Zotero/storage/Y2I2HT6P/Mulder et al. - 2012 - BIEMS  A Fortran 90 Program for Cal.pdf}
}

@article{mulderEditorsIntroductionSpecial2016,
  title = {Editors’ Introduction to the Special Issue “{{Bayes}} Factors for Testing Hypotheses in Psychological Research: Practical Relevance and New Developments”},
  shorttitle = {Editors’ Introduction to the Special Issue “{{Bayes}} Factors for Testing Hypotheses in Psychological Research},
  author = {Mulder, Joris and Wagenmakers, Eric-Jan},
  date = {2016-06},
  journaltitle = {Journal of Mathematical Psychology},
  shortjournal = {Journal of Mathematical Psychology},
  volume = {72},
  pages = {1--5},
  issn = {00222496},
  doi = {10.1016/j.jmp.2016.01.002},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0022249616000043},
  urldate = {2021-07-15},
  abstract = {In order to test their hypotheses, psychologists increasingly favor the Bayes factor, the standard Bayesian measure of relative evidence between two competing statistical models. The Bayes factor has an intuitive interpretation and allows a comparison between any two models, even models that are complex and nonnested. In this introduction to the special issue ‘‘Bayes factors for Testing Hypotheses in Psychological Research: Practical Relevance and New Developments’’, we first highlight the basic properties of the Bayes factor, stressing its advantages over classical significance testing. Next, we briefly discuss statistical software packages that are useful for researchers who wish to make the transition from p values to Bayes factors. We end by providing an overview of the contributions to this special issue. The contributions fall in three partly overlapping categories: those that present new philosophical insights, those that provide methodological innovations, and those that demonstrate practical applications.},
  langid = {english},
  file = {/Users/claudio/MEGA/Zotero/Mulder_Wagenmakers_2016_Editors’ introduction to the special issue “Bayes factors for testing.pdf;/Users/claudio/Zotero/storage/6I6GXZWY/Mulder and Wagenmakers - 2016 - Editors’ introduction to the special issue “Bayes .pdf}
}

@article{mulderPriorAdjustedDefault2014,
  ids = {mulderPriorAdjustedDefault2014a},
  title = {Prior Adjusted Default {{Bayes}} Factors for Testing (in){{Equality}} Constrained Hypotheses},
  author = {Mulder, Joris},
  date = {2014-03},
  journaltitle = {Computational Statistics \& Data Analysis},
  shortjournal = {Computational Statistics \& Data Analysis},
  volume = {71},
  pages = {448--463},
  issn = {01679473},
  doi = {10.1016/j.csda.2013.07.017},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167947313002624},
  urldate = {2021-08-06},
  abstract = {A new method is proposed for testing multiple hypotheses with equality and inequality constraints on the parameters of interest. The method is based on the fractional Bayes factor with a modification that the updated prior is centered on the boundary of the constrained parameter space under investigation. The resulting prior adjusted default Bayes factors work as an ‘‘Ockham’s razor’’ when testing inequality constrained hypotheses, which is not the case for the fractional Bayes factor. Two different types of prior adjusted default Bayes factors are considered. In the first type, the updated prior is based on imaginary training data. Analytical and numerical examples show that this criterion converges fastest to a true inequality constrained hypothesis. In the second type, the updated prior is based on empirical training data. This second criterion only outperforms the fractional Bayes factor in the case of small samples.},
  langid = {english},
  file = {/Users/claudio/MEGA/Zotero/Mulder_2014_Prior adjusted default Bayes factors for testing (in)Equality constrained.pdf;/Users/claudio/Zotero/storage/88KJBG98/Mulder - 2014 - Prior adjusted default Bayes factors for testing (.pdf}
}

@article{mulderSimpleBayesianTesting2019,
  title = {Simple {{Bayesian}} Testing of Scientific Expectations in Linear Regression Models},
  author = {Mulder, J. and Olsson-Collentine, A.},
  date = {2019-06},
  journaltitle = {Behavior Research Methods},
  shortjournal = {Behav Res},
  volume = {51},
  number = {3},
  pages = {1117--1130},
  issn = {1554-3528},
  doi = {10.3758/s13428-018-01196-9},
  url = {http://link.springer.com/10.3758/s13428-018-01196-9},
  urldate = {2021-06-07},
  abstract = {Scientific theories can often be formulated using equality and order constraints on the relative effects in a linear regression model. For example, it may be expected that the effect of the first predictor is larger than the effect of the second predictor, and the second predictor is expected to be larger than the third predictor. The goal is then to test such expectations against competing scientific expectations or theories. In this paper, a simple default Bayes factor test is proposed for testing multiple hypotheses with equality and order constraints on the effects of interest. The proposed testing criterion can be computed without requiring external prior information about the expected effects before observing the data. The method is implemented in R-package called ‘lmhyp’ which is freely downloadable and ready to use. The usability of the method and software is illustrated using empirical applications from the social and behavioral sciences.},
  langid = {english},
  file = {/Users/claudio/MEGA/Zotero/Mulder_Olsson-Collentine_2019_Simple Bayesian testing of scientific expectations in linear regression models.pdf;/Users/claudio/Zotero/storage/Y7XIJBMW/Mulder_Olsson-Collentine_2019_Simple Bayesian testing of scientific expectations in linear regression models.pdf}
}

@article{nakagawaCoefficientDeterminationR22017,
  title = {The Coefficient of Determination {{R2}} and Intra-Class Correlation Coefficient from Generalized Linear Mixed-Effects Models Revisited and Expanded},
  author = {Nakagawa, Shinichi and Johnson, Paul C D and Schielzeth, Holger},
  date = {2017},
  journaltitle = {Journal of The Royal Society Interface},
  number = {14},
  pages = {20170213},
  doi = {http://dx.doi.org/10.1098/rsif.2017.0213},
  langid = {english},
  file = {/Users/claudio/MEGA/Zotero/Nakagawa et al_2017_The coefficient of determination R2 and intra-class correlation coefficient.pdf}
}

@article{ohaganFractionalBayesFactors1995,
  title = {Fractional {{Bayes Factors}} for {{Model Comparison}}},
  author = {O'Hagan, Anthony},
  date = {1995},
  journaltitle = {Journal of the Royal Statistical Society. Series B (Methodological)},
  volume = {57},
  number = {1},
  eprint = {2346088},
  eprinttype = {jstor},
  pages = {99--138},
  publisher = {{[Royal Statistical Society, Wiley]}},
  issn = {00359246},
  abstract = {[Bayesian comparison of models is achieved simply by calculation of posterior probabilities of the models themselves. However, there are difficulties with this approach when prior information about the parameters of the various models is weak. Partial Bayes factors offer a resolution of the problem by setting aside part of the data as a training sample. The training sample is used to obtain an initial informative posterior distribution of the parameters in each model. Model comparison is then based on a Bayes factor calculated from the remaining data. Properties of partial Bayes factors are discussed, particularly in the context of weak prior information, and they are found to have advantages over other proposed methods of model comparison. A new variant of the partial Bayes factor, the fractional Bayes factor, is advocated on grounds of consistency, simplicity, robustness and coherence.]}
}

@manual{rcoreteamLanguageEnvironmentStatistical2021,
  type = {manual},
  title = {R: A Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  date = {2021},
  location = {{Vienna, Austria}},
  url = {https://www.R-project.org/},
  organization = {{R Foundation for Statistical Computing}}
}

@article{rodrigues-mottaZeroInflatedPoissonModel2007,
  title = {A {{Zero}}-{{Inflated Poisson Model}} for {{Genetic Analysis}} of the {{Number}} of {{Mastitis Cases}} in {{Norwegian Red Cows}}},
  author = {Rodrigues-Motta, M. and Gianola, D. and Heringstad, B. and Rosa, G.J.M. and Chang, Y.M.},
  date = {2007-11},
  journaltitle = {Journal of Dairy Science},
  shortjournal = {Journal of Dairy Science},
  volume = {90},
  number = {11},
  pages = {5306--5315},
  issn = {00220302},
  doi = {10.3168/jds.2006-898},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0022030207720003},
  urldate = {2021-05-31},
  abstract = {The objective was to extend a zero-inflated Poisson (ZIP) model to account for correlated genetic effects, and to use this model to analyze the number of clinical mastitis cases in Norwegian Red cows. The ZIP model is suitable for analysis of count data containing an excess of zeros relative to what is expected from Poisson sampling. A ZIP model was developed and compared with a corresponding Poisson model. The Poisson parameter followed a hierarchical structure, and a residual term accounting for overdispersion was included. In both models, the Poisson parameter was regressed 1) on the year, month, and age at first calving; 2) on the logarithm of the number of days elapsed from calving to the end of first lactation; and c) on herd and sire effects. Herd and sire effects were assigned normal prior distributions in a Bayesian analysis, corresponding to a random effects treatment in a frequentist analysis. An analysis of residuals favored the Poisson model when there were 2 or more cases of mastitis during first lactation, with very small differences between the ZIP and Poisson models at 0 and 1 cases. However, the residual assessment was not satisfactory for either of the models. The ZIP model, on the other hand, had a better predictive ability than the corresponding Poisson model. Posterior means of the sire, herd, and residual variances in the ZIP model (log scale) were 0.09, 0.37, and 0.36, respectively, highlighting the importance of herds as a source of variation in clinical mastitis. The correlation between sire rankings from the ZIP and Poisson models was 0.98. A weaker correlation would be expected in a population with more severe inflation at zero than the present one. The estimate of the perfect state probability p was 0.32, indicating that 32\% of the animals would be in the perfect state, either because they are resistant or because they were not exposed to mastitis.},
  langid = {english},
  keywords = {Letto Parzialmente},
  file = {/Users/claudio/MEGA/Zotero/Rodrigues-Motta et al_2007_A Zero-Inflated Poisson Model for Genetic Analysis of the Number of Mastitis.pdf;/Users/claudio/Zotero/storage/3YUADYFB/Rodrigues-Motta et al. - 2007 - A Zero-Inflated Poisson Model for Genetic Analysis.pdf}
}

@article{rodriguesBayesianAnalysisZeroInflated2003,
  title = {Bayesian {{Analysis}} of {{Zero}}-{{Inflated Distributions}}},
  author = {Rodrigues, Josemar},
  date = {2003-01-03},
  journaltitle = {Communications in Statistics - Theory and Methods},
  shortjournal = {Communications in Statistics - Theory and Methods},
  volume = {32},
  number = {2},
  pages = {281--289},
  issn = {0361-0926, 1532-415X},
  doi = {10.1081/STA-120018186},
  url = {http://www.tandfonline.com/doi/abs/10.1081/STA-120018186},
  urldate = {2021-05-28},
  abstract = {In this paper zero-inflated distributions (ZID) are studied from the Bayesian point of view using the data augmentation algorithm. This type of discrete model arises in count data with excess of zeros. The zero-inflated Poisson distribution (ZIP) and an illustrative example via MCMC algorithm are considered.},
  langid = {english},
  file = {/Users/claudio/MEGA/Zotero/Rodrigues_2003_Bayesian Analysis of Zero-Inflated Distributions.pdf;/Users/claudio/Zotero/storage/YFDYQKLH/Rodrigues - 2003 - Bayesian Analysis of Zero-Inflated Distributions.pdf}
}

@article{rodriguez-yamEfficientGibbsSampling,
  title = {Efficient {{Gibbs Sampling}} for {{Constrained Linear Regression}}},
  author = {Rodriguez-Yam, Gabriel and Davis, Richard A and Scharf, Louis L},
  pages = {6},
  abstract = {In this paper we consider parameter estimation in a linear regression setting with inequality linear constraints on the regression parameters. Most other research on this topic has typically been addressed from a Bayesian perspective. Geweke (1996) and Chen and Deely (1996) implemented the Gibbs sampler to generate samples from the posterior distribution. However, these implementations can often exhibit poor mixing and slow convergence. This paper overcomes these limitations with a new implementation of the Gibbs sampler. In addition, this procedure allows for the number of constraints to exceed the parameter dimension and is able to cope with equality linear constraints.},
  langid = {english},
  file = {/Users/claudio/MEGA/Zotero/Rodriguez-Yam et al_Efficient Gibbs Sampling for Constrained Linear Regression.pdf;/Users/claudio/Zotero/storage/XTSV2X3F/Rodriguez-Yam et al. - Eﬃcient Gibbs Sampling for Constrained Linear Regr.pdf}
}

@article{schadHowCapitalizePriori2020,
  ids = {schadHowCapitalizePriori2019},
  title = {How to Capitalize on a Priori Contrasts in Linear (Mixed) Models: A Tutorial},
  author = {Schad, Daniel J. and Vasishth, Shravan and Hohenstein, Sven and Kliegl, Reinhold},
  date = {2020-02-01},
  journaltitle = {Journal of Memory and Language},
  shortjournal = {Journal of Memory and Language},
  volume = {110},
  eprint = {1807.10451},
  eprinttype = {arxiv},
  pages = {104038},
  issn = {0749-596X},
  doi = {10.1016/j.jml.2019.104038},
  url = {https://www.sciencedirect.com/science/article/pii/S0749596X19300695},
  abstract = {Factorial experiments in research on memory, language, and in other areas are often analyzed using analysis of variance (ANOVA). However, for effects with more than one numerator degrees of freedom, e.g., for experimental factors with more than two levels, the ANOVA omnibus F-test is not informative about the source of a main effect or interaction. Because researchers typically have specific hypotheses about which condition means differ from each other, a priori contrasts (i.e., comparisons planned before the sample means are known) between specific conditions or combinations of conditions are the appropriate way to represent such hypotheses in the statistical model. Many researchers have pointed out that contrasts should be “tested instead of, rather than as a supplement to, the ordinary ‘omnibus’ F test” (Hays, 1973, p. 601). In this tutorial, we explain the mathematics underlying different kinds of contrasts (i.e., treatment, sum, repeated, polynomial, custom, nested, interaction contrasts), discuss their properties, and demonstrate how they are applied in the R System for Statistical Computing (R Core Team, 2018). In this context, we explain the generalized inverse which is needed to compute the coefficients for contrasts that test hypotheses that are not covered by the default set of contrasts. A detailed understanding of contrast coding is crucial for successful and correct specification in linear models (including linear mixed models). Contrasts defined a priori yield far more useful confirmatory tests of experimental hypotheses than standard omnibus F-tests. Reproducible code is available from https://osf.io/7ukf6/.},
  archiveprefix = {arXiv},
  keywords = {A priori hypotheses,Contrasts,Letto,Linear models,Null hypothesis significance testing,Statistics - Methodology},
  file = {/Users/claudio/MEGA/Zotero/Schad et al_2019_How to capitalize on a priori contrasts in linear (mixed) models.pdf;/Users/claudio/MEGA/Zotero/Schad et al_2020_How to capitalize on a priori contrasts in linear (mixed) models.pdf}
}

@article{schadPrincipledBayesianWorkflow2021,
  title = {Toward a Principled {{Bayesian}} Workflow in Cognitive Science.},
  author = {Schad, Daniel J. and Betancourt, Michael and Vasishth, Shravan},
  date = {2021},
  journaltitle = {Psychological Methods},
  volume = {26},
  number = {1},
  pages = {103--126},
  publisher = {{American Psychological Association}},
  location = {{US}},
  issn = {1939-1463(Electronic),1082-989X(Print)},
  doi = {10.1037/met0000275},
  abstract = {Experiments in research on memory, language, and in other areas of cognitive science are increasingly being analyzed using Bayesian methods. This has been facilitated by the development of probabilistic programming languages such as Stan, and easily accessible front-end packages such as brms. The utility of Bayesian methods, however, ultimately depends on the relevance of the Bayesian model, in particular whether or not it accurately captures the structure of the data and the data analyst’s domain expertise. Even with powerful software, the analyst is responsible for verifying the utility of their model. To demonstrate this point, we introduce a principled Bayesian workflow (Betancourt, 2018) to cognitive science. Using a concrete working example, we describe basic questions one should ask about the model: prior predictive checks, computational faithfulness, model sensitivity, and posterior predictive checks. The running example for demonstrating the workflow is data on reading times with a linguistic manipulation of object versus subject relative clause sentences. This principled Bayesian workflow also demonstrates how to use domain knowledge to inform prior distributions. It provides guidelines and checks for valid data analysis, avoiding overfitting complex models to noise, and capturing relevant data structure in a probabilistic model. Given the increasing use of Bayesian methods, we aim to discuss how these methods can be properly employed to obtain robust answers to scientific questions. All data and code accompanying this article are available from https://osf.io/b2vx9/. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
  keywords = {*Cognitive Science,*Prediction,*Probability,Bayesian Analysis,Computer Programming Languages,Experience Level,Flow (Consciousness State),Memory}
}

@online{schadWorkflowTechniquesRobust2021,
  title = {Workflow {{Techniques}} for the {{Robust Use}} of {{Bayes Factors}}},
  author = {Schad, Daniel J. and Nicenboim, Bruno and Bürkner, Paul-Christian and Betancourt, Michael and Vasishth, Shravan},
  date = {2021-03-18},
  eprint = {2103.08744},
  eprinttype = {arxiv},
  primaryclass = {stat},
  url = {http://arxiv.org/abs/2103.08744},
  urldate = {2021-08-18},
  abstract = {Inferences about hypotheses are ubiquitous in the cognitive sciences. Bayes factors provide one general way to compare different hypotheses by their compatibility with the observed data. Those quantifications can then also be used to choose between hypotheses. While Bayes factors provide an immediate approach to hypothesis testing, they are highly sensitive to details of the data/model assumptions. Moreover it’s not clear how straightforwardly this approach can be implemented in practice, and in particular how sensitive it is to the details of the computational implementation. Here, we investigate these questions for Bayes factor analyses in the cognitive sciences. We explain the statistics underlying Bayes factors as a tool for Bayesian inferences and discuss that utility functions are needed for principled decisions on hypotheses. Next, we study how Bayes factors misbehave under different conditions. This includes a study of errors in the estimation of Bayes factors. Importantly, it is unknown whether Bayes factor estimates based on bridge sampling are unbiased for complex analyses. We are the first to use simulation-based calibration as a tool to test the accuracy of Bayes factor estimates. Moreover, we study how stable Bayes factors are against different MCMC draws. We moreover study how Bayes factors depend on variation in the data. We also look at variability of decisions based on Bayes factors and how to optimize decisions using a utility function. We outline a Bayes factor workflow that researchers can use to study whether Bayes factors are robust for their individual analysis, and we illustrate this workflow using an example from the cognitive sciences. We hope that this study will provide a workflow to test the strengths and limitations of Bayes factors as a way to quantify evidence in support of scientific hypotheses. Reproducible code is available from https://osf.io/y354c/.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {/Users/claudio/MEGA/Zotero/Schad et al_2021_Workflow Techniques for the Robust Use of Bayes Factors.pdf;/Users/claudio/Zotero/storage/TF7SYYJK/Schad et al_2021_Workflow Techniques for the Robust Use of Bayes Factors.pdf}
}

@article{schwarzEstimatingDimensionModel1978,
  title = {Estimating the Dimension of a Model},
  author = {Schwarz, Gideon},
  date = {1978},
  journaltitle = {The annals of statistics},
  shortjournal = {The annals of statistics},
  volume = {6},
  number = {2},
  pages = {461--464},
  issn = {0090-5364},
  file = {/Users/claudio/MEGA/Zotero/Schwarz_1978_Estimating the dimension of a model.pdf}
}

@article{scruccaMclustClusteringClassification2016,
  title = {{{mclust}} 5: Clustering, Classification and Density Estimation Using {{Gaussian}} Finite Mixture Models},
  author = {Scrucca, Luca and Fop, Michael and Murphy, T. Brendan and Raftery, Adrian E.},
  date = {2016},
  journaltitle = {The R Journal},
  volume = {8},
  number = {1},
  pages = {289--317},
  url = {https://doi.org/10.32614/RJ-2016-021}
}

@online{simonsohn78aIfYou2019,
  title = {[78a] {{If}} You Think p-Values Are Problematic, Wait until You Understand {{Bayes Factors}}},
  author = {Simonsohn, Uri},
  date = {2019-09-06T11:01:28+00:00},
  url = {http://datacolada.org/78a},
  urldate = {2021-08-18},
  abstract = {Would raising the minimum wage by \$4 lead to greater unemployment? Milton, a Chicago economist, has a theory (supply and demand) that says so. Milton believes the causal effect is anywhere between 1\% and 10\%. After the minimum wage increase of \$4, unemployment goes up 1\%.~ Milton feels bad about the unemployed but good about...},
  langid = {american},
  organization = {{Data Colada}},
  file = {/Users/claudio/Zotero/storage/9VWIAUQA/78a.html;/Users/claudio/Zotero/storage/PKXP6SWL/78a.html}
}

@misc{standevelopmentteamRStanInterfaceStan2020,
  title = {{{RStan}}: The {{R}} Interface to {{Stan}}},
  author = {{Stan Development Team}},
  date = {2020},
  url = {http://mc-stan.org/}
}

@article{vandeschootIntroductionBayesianModel2011,
  title = {An Introduction to {{Bayesian}} Model Selection for Evaluating Informative Hypotheses},
  author = {van de Schoot, Rens and Mulder, Joris and Hoijtink, Herbert and Van Aken, Marcel A. G. and Semon Dubas, Judith and Orobio de Castro, Bram and Meeus, Wim and Romeijn, Jan-Willem},
  options = {useprefix=true},
  date = {2011-11},
  journaltitle = {European Journal of Developmental Psychology},
  volume = {8},
  number = {6},
  pages = {713--729},
  issn = {1740-5629, 1740-5610},
  doi = {10.1080/17405629.2011.621799},
  url = {http://www.tandfonline.com/doi/abs/10.1080/17405629.2011.621799},
  urldate = {2019-05-22},
  langid = {english},
  keywords = {Bayesian,Informative Hypotesis,Letto,Model Comparison},
  file = {/Users/claudio/MEGA/Zotero/van de Schoot et al_2011_An introduction to Bayesian model selection for evaluating informative.pdf;/Users/claudio/MEGA/Zotero/van de Schoot et al_2011_An introduction to Bayesian model selection for evaluating informative2.pdf;/Users/claudio/Zotero/storage/2Z47MW36/van de Schoot et al_2011_An introduction to Bayesian model selection for evaluating informative2.pdf;/Users/claudio/Zotero/storage/TTKLCQ2L/van de Schoot et al_2011_An introduction to Bayesian model selection for evaluating informative.pdf}
}

@manual{varadhanCondMVNormConditionalMultivariate2020,
  type = {manual},
  title = {{{condMVNorm}}: Conditional Multivariate Normal Distribution},
  author = {Varadhan, Ravi},
  date = {2020},
  url = {https://CRAN.R-project.org/package=condMVNorm}
}

@book{venablesModernAppliedStatistics2002a,
  title = {Modern Applied Statistics with s},
  author = {Venables, W. N. and Ripley, B. D.},
  date = {2002},
  edition = {4},
  publisher = {{Springer}},
  location = {{New York}},
  url = {https://www.stats.ox.ac.uk/pub/MASS4/}
}

@article{wagenmakersAICModelSelection2004,
  ids = {wagenmakers2004a,wagenmakersAICModelSelection2004a},
  title = {{{AIC}} Model Selection Using {{Akaike}} Weights},
  author = {Wagenmakers, Eric-Jan and Farrell, Simon},
  date = {2004-02},
  journaltitle = {Psychonomic Bulletin \& Review},
  volume = {11},
  number = {1},
  pages = {192--196},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/BF03206482},
  url = {http://www.springerlink.com/index/10.3758/BF03206482},
  urldate = {2019-01-16},
  langid = {english},
  keywords = {AIC,AIC weights,BIC,Letto,Model Comparison},
  file = {/Users/claudio/MEGA/Zotero/Wagenmakers_Farrell_2004_AIC model selection using Akaike weights.pdf}
}

@article{wagenmakersBayesianHypothesisTesting2010,
  title = {Bayesian Hypothesis Testing for Psychologists: A Tutorial on the {{Savage}}–{{Dickey}} Method},
  shorttitle = {Bayesian Hypothesis Testing for Psychologists},
  author = {Wagenmakers, Eric-Jan and Lodewyckx, Tom and Kuriyal, Himanshu and Grasman, Raoul},
  date = {2010-05},
  journaltitle = {Cognitive Psychology},
  shortjournal = {Cognitive Psychology},
  volume = {60},
  number = {3},
  pages = {158--189},
  issn = {00100285},
  doi = {10.1016/j.cogpsych.2009.12.001},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0010028509000826},
  urldate = {2021-05-25},
  abstract = {In the field of cognitive psychology, the p-value hypothesis test has established a stranglehold on statistical reporting. This is unfortunate, as the p-value provides at best a rough estimate of the evidence that the data provide for the presence of an experimental effect. An alternative and arguably more appropriate measure of evidence is conveyed by a Bayesian hypothesis test, which prefers the model with the highest average likelihood. One of the main problems with this Bayesian hypothesis test, however, is that it often requires relatively sophisticated numerical methods for its computation. Here we draw attention to the Savage–Dickey density ratio method, a method that can be used to compute the result of a Bayesian hypothesis test for nested models and under certain plausible restrictions on the parameter priors. Practical examples demonstrate the method’s validity, generality, and flexibility.},
  langid = {english},
  file = {/Users/claudio/MEGA/Zotero/Wagenmakers et al_2010_Bayesian hypothesis testing for psychologists.pdf;/Users/claudio/Zotero/storage/YDPVNINF/Wagenmakers et al. - 2010 - Bayesian hypothesis testing for psychologists A t.pdf}
}

@article{wasserstein2019moving,
  ids = {an,wassersteinMovingWorld052019},
  title = {Moving to a World beyond “P{$<$} 0.05”},
  author = {Wasserstein, Ronald L and Schirm, Allen L and Lazar, Nicole A},
  date = {2019},
  journaltitle = {The American Statistician},
  volume = {73},
  pages = {1--19},
  publisher = {{Taylor \& Francis}},
  doi = {10.1080/00031305.2019.1583913},
  url = {https://doi.org/10.1080/00031305.2019.1583913},
  issue = {sup1},
  file = {/Users/claudio/MEGA/Zotero/Wasserstein et al_2019_Moving to a World Beyond “ ip-i 0.pdf;/Users/claudio/MEGA/Zotero/Wasserstein et al_2019_Moving to a world beyond “P 0.pdf}
}

@article{wetzelsEncompassingPriorGeneralization2010,
  title = {An Encompassing Prior Generalization of the {{Savage}}–{{Dickey}} Density Ratio},
  author = {Wetzels, Ruud and Grasman, Raoul P.P.P. and Wagenmakers, Eric-Jan},
  date = {2010-09-01},
  journaltitle = {Computational Statistics \& Data Analysis},
  shortjournal = {Computational Statistics \& Data Analysis},
  volume = {54},
  number = {9},
  pages = {2094--2102},
  issn = {0167-9473},
  doi = {10.1016/j.csda.2010.03.016},
  url = {https://www.sciencedirect.com/science/article/pii/S0167947310001180},
  abstract = {An encompassing prior (EP) approach to facilitate Bayesian model selection for nested models with inequality constraints has been previously proposed. In this approach, samples are drawn from the prior and posterior distributions of an encompassing model that contains an inequality restricted version as a special case. The Bayes factor in favor of the inequality restriction then simplifies to the ratio of the proportions of posterior and prior samples consistent with the inequality restriction. This formalism has been applied almost exclusively to models with inequality or “about equality” constraints. It is shown that the EP approach naturally extends to exact equality constraints by considering the ratio of the heights for the posterior and prior distributions at the point that is subject to test (i.e.,~the Savage–Dickey density ratio). The EP approach generalizes the Savage–Dickey ratio method, and can accommodate both inequality and exact equality constraints. The general EP approach is found to be a computationally efficient procedure to calculate Bayes factors for nested models. However, the EP approach to exact equality constraints is vulnerable to the Borel–Kolmogorov paradox, the consequences of which warrant careful consideration.},
  keywords = {Bayesian model selection,Borel–Kolmogorov paradox,Equality constraints,Hypothesis testing,Inequality constraints}
}

@article{zeileisRegressionModelsCount2008,
  title = {Regression Models for Count Data in {{R}}},
  author = {Zeileis, Achim and Kleiber, Christian and Jackman, Simon},
  date = {2008},
  journaltitle = {Journal of Statistical Software},
  volume = {27},
  number = {8},
  url = {http://www.jstatsoft.org/v27/i08/}
}

@inbook{zellnerPosteriorOddsRatios1980,
  title = {Posterior Odds Ratios for Selected Regression Hypotheses. {{M}}. {{H}}. , {{D}}. {{V}}. {{Lindley}}, \& {{A}}. {{F}}. {{M}}. {{Smith}} ({{Eds}}.),},
  booktitle = {Bayesian Statistics: Proceedings of the {{First International Meeting}} Held in {{Valencia}} ({{Spain}})},
  author = {Zellner, A. and Siow, A.},
  date = {1980},
  pages = {pp. 585--603},
  publisher = {{University of Valencia}},
  bookauthor = {Bernardo, J. M. and DeGroot, M. H. and Lindley, D. V. and Smith, A.F.M.}
}


