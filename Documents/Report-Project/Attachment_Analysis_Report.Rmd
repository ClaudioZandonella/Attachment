---
title: 'Attachment Analysis: Report Project'
author: 'CZC, TM & GA'
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  bookdown::html_document2: 
    toc: true
    toc_depth: 3
    toc_float: true
    collapsed: false
    css: ["css/custom.css"]
linestretch: 1.5
number_sections: true
bibliography: "../Biblio-attachment.bib"
csl: apa.csl
link-citations: true 
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, collapse = TRUE)

library(tidyverse)
library(kableExtra)
library(mclust)

devtools::load_all("../../")

path_drake <- "../../.drake"

#----    load drake    ----

# Data
drake::loadd(raw_data)
drake::loadd(data_munged)
drake::loadd(data_cluster)

# Cluster
drake::loadd(cluster_mother_fit)
drake::loadd(cluster_father_fit)

drake::loadd(mclust_mother)
drake::loadd(mclust_father)

# ZIP anlaysis
drake::loadd(fit_int_poisson)

# ANOVA
drake::loadd(fit_int_zip)

# brms models
drake::loadd(brm_int_mother)
drake::loadd(waic_weights_int)
drake::loadd(loo_weights_int)

# BF encompassing
drake::loadd(fit_H1)
```

In this report, preliminary results of the analysis are presented considering as dependent variable internalizing problems. Note the actual paper will consider externalizing problems, instead. (**Spoiler**: with externalizing problems models present more interesting results. However, here we used internalizing problems as an example to introduce the analysis method avoiding to influence the subsequent expert elicitation regarding externalizing problems).

# Introduction

## Backgorund

The aim of the analysis is to compare the 4 main theories regarding the role of child-mother  and child-father attachment on children development. In brief:

1. **Monotropy Theory** - only the mother is important
1. **Hierarchical Theory** -  the mother is more important than the father
1. **Independent Theory** - mother and father affect different area of children development
1. **Interaction Theory** - mother and father interact  

Here we evaluate as dependent variable:

- **Internalizing Problems** - given by the sum of the SDQ (*Strengths & Difficulties Questionnaires*)

As independent variable we consider:

- **Gender** - children gender
- **Mother Attachment** - considering clusters obtained from the ECR questionnaire
- **Father Attachment** - considering clusters obtained from the ECR questionnaire

## Analysis Plan

First, we present descriptive statistics and cluster analysis of mother and father attachment. Subsequently we present three different analyses discussing pro and con of each approach. In particular we adopted:

1. Tradition ANOVA analysis. (Note that actually is Analysisi of Deviance)
1. Bayesian Model Comparison
1. Bayes Factor with Encompassing Priors

In all cases, Zero Inflated Poisson (*ZIP*) models were used to take into account the distribution characteristics of the dependent variable. This issue is discussed below.

# Descriptive Statistics

The sample size is:

```{r sample-size, echo = TRUE}
nrow(data_cluster)
```


#### Age {-}

Summary statistics of children age (in years).

```{r, echo = TRUE}
summary(raw_data$age_year)
sd(raw_data$age_year, na.rm = TRUE)
```

```{r, plot-age}
ggplot(raw_data) +
  geom_histogram(aes(x = age_year), col = "grey40", fill = "#00BFC4") +
  theme_bw()
```

Children school grade frequancy

```{r}
table(raw_data$classe)
```

#### Gender {-}

```{r}
table(data_cluster$gender)
```

## Cluster Analysis

### Mother

From the cluster analysis, 4 groups were selected.

```{r, plot-cluster-mother}
plot(cluster_mother_fit, main = "Dendrogramma")
rect.hclust(cluster_mother_fit, k=4, border="red")
```

Frequencies of the clusters are

```{r, echo = TRUE}
table(data_cluster$mother)

prop.table(table(data_cluster$mother))

prop.table(table(data_cluster$mother,
                 data_cluster$gender),2) 

summary(table(data_cluster$mother,
              data_cluster$gender))
```

Plot of average Anxiety and Avoidance scores in the four clusters

```{r, plot-scores-mother}
plot_scores_mother(data = data_cluster)
```

#### Mclust check {-}

```{r, plot-mclust-mother}
plot(mclust_mother)
summary(mclust_mother)
```


### Father

From the cluster analysis, 4 groups were selected.

```{r, plot-cluster-father}
plot(cluster_father_fit, main = "Dendrogramma")
rect.hclust(cluster_father_fit, k=4, border="red")
```

Frequencies of the clusters are

```{r, echo = TRUE}
table(data_cluster$father)

prop.table(table(data_cluster$father))

prop.table(table(data_cluster$father,
                 data_cluster$gender),2) 

summary(table(data_cluster$father,
              data_cluster$gender))
```

Plot of average Anxiety and Avoidance scores in the four clusters

```{r, plot-scores-father}
plot_scores_father(data = data_cluster)
```

#### Mclust check {-}

```{r, plot-mclust-father}
plot(mclust_father)
summary(mclust_father)
```

### Mother & Father

Overall frequencies of mother and father attachment
```{r, echo = TRUE}
table(data_cluster$mother, data_cluster$father)

round(prop.table(table(data_cluster$mother, data_cluster$father)),3)

table(data_cluster$mother, data_cluster$father, data_cluster$gender)
```


## Dependent Variable

### Internalizing

Distribution of internalizing problems
```{r, plot-internalizing}
ggplot(data_cluster) +
  geom_bar(aes(x = internalizing_sum), col = "gray40", fill = "#00BFC4", alpha = 0.7) +
  theme_bw()
```

Internalizing according to gender 

```{r, plot-internalizing-gender}
ggplot(data_cluster) +
  geom_bar(aes(x = internalizing_sum, fill = gender), col = "gray40", 
           alpha = 0.7, show.legend = FALSE) +
  facet_grid(gender ~ .) +
  theme_bw() 
```

#### Zero Inflation {-}

Considering the distribution of internalizing scores it seems that there is an inflation of zero. To evaluate that we fit a poisson model and we compare the number of observed zero and expected zero.

```{r, echo = TRUE, eval = FALSE}
# model formula
internalizing_sum ~ gender + cluster_mother * cluster_father
```

```{r, echo = TRUE}
fit_int_poisson
```

```{r, echo = TRUE}
performance::check_zeroinflation(fit_int_poisson)
```

Results indicate that the model is underfitting zeros. Thus in the analysis we will use a Zero inflated Poisson (*ZIP*) model.

# Statistical Analysis 

In all subsequent analysis we considered Zero Inflated Poisson (ZIP) models:

$$
y_i \sim ZIPoisson(p_i, \lambda_i)
$$

Where, $p_i$ is the probability of an observation $y_i$ being an extra zero (i.e., a zero not comming from the poisson distribution) and $1 - p_i$ indicates the probability of given observation $y_i$ being generated from a Poisson distribution with mean $\lambda_i$. In particular,

$$
p_i = \text{logit}^{-1}(X_i^T\beta_{p}),\\
\lambda_i = \text{exp}(X_i^T\beta_{\lambda}).
$$

That is, we want to model both $p_i$ and $\lambda_i$ according to a set of independent variables. Thus we have to estimate parameters vector $\beta_p$ and $\beta_{\lambda}$ respectively. Note that these are the only parameters in the model.

In particular we considered as predictors:

```{r, echo = TRUE, eval = FALSE}
# formula for p
p ~ gender

# formula for lambda
lambda ~ gender + ...
```

That is, we model the probability ($p_i$) of an observation being zero or coming from a poisson distribution according to `gender`. Whereas, we model the poisson mean ($\lambda_i$) according to `gender` and other variables among `cluster_mother` and `cluster_father`.


## ANOVA Approach

Classical approach is to fit the most complex model. Subsequently, ANOVA or likelihood ratio test are computed to evaluate the significance of the predictors. Finally, according to the results, researcher evaluate if hypothesis are supported or not.

In our case we fit a model considering the interaction between `cluster_mother` and `cluster_father`. That is:
```{r, echo = TRUE, eval = FALSE}
# formula for p
p ~ gender

# formula for lambda
lambda ~ gender + mother * father
```

Than we conduct an ANOVA using the `car`. Note that as we are using a GLM we are actually conducting an Analysis of Deviance.

```{r, echo = TRUE}
car::Anova(fit_int_zip)
```

In this case we get that the interaction is significant. Thus results support the **Interaction Theory**.

Summary of the model:
```{r, echo = TRUE}
summary(fit_int_zip)
```

R squared:

```{r, echo = TRUE}
rcompanion::nagelkerke(fit_int_zip)
```

**TODO** - plot of the effects (below are effects from the normal poisson model)

```{r, plot-ANOVA-effects}
plot(effects::effect(mod = fit_int_poisson, term = "mother * father"))
```

### Consideration

The problem here is to evaluate which are the actual differences of interests. Are we modeling relevant effects or random noise? We are not penalizing for complexity of the model.

Moreover we are not comparing dirrectly the hypothesis of interest but just doing testing.

## Bayesian Model Comparison Approach

We compare 4 models. In all models $p_i$ is predicted by gender, whereas predictors of $\lambda_i$ are selected according to the different hypothesis:

1. `brm_int_zero`: $\lambda_i \sim$ `gender`
1. `brm_int_mother`: $\lambda_i \sim$ `gender + mother`
1. `brm_int_additive`: $\lambda_i \sim$ `gender + mother + father`
1. `brm_int_inter`: $\lambda_i \sim$ `gender + mother * father`

Models were estimated using in `brms` using default prior settings.

```{r, echo = TRUE}
brms::prior_summary(brm_int_mother)
```

Model comparison approach using waic index:

```{r, echo = TRUE}
waic_weights_int
```

and loo index

```{r, echo = TRUE}
loo_weights_int
```

The *preferred* model is the one considering only the role of mother attachment. Results support the
**Monotropy Theory**.

### `brm_int_mother`

Model summary. Note that `brms` indicates $p_i$ with `zi`.

```{r, echo = TRUE}
summary(brm_int_mother)
```

Plot effects

```{r, plot-effects-brm_int_mother}
plot(brms::conditional_effects(brm_int_mother), ask = FALSE)
```

Posterior Predictive Check
```{r}
brms::pp_check(brm_int_mother, nsamples = 25)
```

**TODO** - not really a good fit, clear sign of over-dispersion. Probably Negative binomial would be better than poisson.

R squarded

```{r, echo = TRUE}
brms::bayes_R2(brm_int_mother)
```

### Considerations

Overall fit is pretty bad. However, this approach allow us to define models according to research hypothesis and compare them taking into account model complexity.

Using this approach, however, there is not a lot of formalization. For example we are not explicitying the expected direction of the effects or the expected order.

## Bayes Factor  Encompassin Prior Approach

With this approach we can explicit equality and order constraints between parameters. Thus a given Hypothesis can be expressed as:
$$
H_i:\ R_E\theta = r_E,\  R_I\theta > r_I
$$

In order to compare informative hypothesis, we define an unconstrained model considered as reference with encompassing priors that are uninformative with respect to the parameters. All other models are nested in this model and the priors ore obtained by restricting the parameter space in accordance with the constraints imposed by each model.

Note that we first need to reparametrize the model as follow:
\begin{align}
&\beta_{eq} = R_{eq}\theta - r_{eq},\\
&\beta_{ineq} = R_{ineq}\theta - r_{ineq}.
\end{align}
These allows as to express constraints as
$$H_i: \beta_{eq} = 0,\ \beta_{ineeq}>0,$$ 
so prior specification is simplified (they are all centered to zero) and with symmetric priors we do  not favor any constraint.

For example for a constraint of type:
$$
0<\theta_1<\theta_2<\theta_3
$$
we would define
$$
d\theta_2:= \theta_2 - \theta_1\\
d\theta_3:= \theta_3 - \theta_2
$$
So wee can express constraints as
$$
\theta_1>0\\
d\theta_2>0\\
d\theta_3>0
$$

Subsequently we can compute the Bayes Factor between an informative hypothesis ($M_i$) and the unconstrain model ($M_u$) as

\begin{aligned}
BF_{iu} = \frac{Pr(\text{Inequality Const} | \text{Equality Const}, \text{Data})}{\pi_u(\text{Inequality Const} | \text{Equality Const})} &\frac{Pr(\text{Equality Const}| \text{Data})}{\pi_u( \text{Equality Const})} = \\ \\  \frac{Pr(R_I\theta > r_I | R_E\theta = r_E, Y)}{\pi_u(R_I\theta > r_I | R_E\theta = r_E)} &\frac{Pr(R_E\theta = r_E| Y)}{\pi_u( R_E\theta = r_E)}.
\end{aligned}

Where, the first part is a ratio between conditional posterior and conditional prior **probabilities** that the inequality constraints hold under $M_u$. The second part is a ratio between  marginal posterior and marginal prior **densities** of the equality constraints under $M_u$, the well-known *Savageâ€“Dickey density ratio*.

### Toy Example


As an example consider these hypothesis considering mother attachment:

$$\text{Mother-Secure} = \text{Mother-Avoidonat} < \text{Mother-Anxious} < \text{Mother-Anxious-Avoidant}$$
Note that we do not define any constrain regarding the father (but we will do it in the actual application).

For simplicity consider as encompassing model the model with only the mother and gender as predictor of $\lambda_i$ (actual application will consider the interaction model). Note that according to the used *treatment-contrast coding* we have:

\begin{align}
&intercept = \text{Mother-Secure Female}\\
&\beta_1 = \text{Gender-Male}\\
&\beta_2 = \text{Mother-Anxious}\\
&\beta_3 = \text{Mother-Avoidonat}\\
&\beta_4 = \text{Mother-Anxious-Avoidant}\\
\end{align}

So we re-parametrize the model as follow
$$
d\beta_4 := \beta_4 -\beta_2
$$
and the constraints we obtain are
$$
\beta_2 > 0\\
\beta_3 = 0\\
d\beta_4 > 0 
$$
Note that $\beta_1$ do not appear in the constraints so is considered as a nuisance parameter together with the intercepts and parameters referiing to $p_i$.

Here the actual stan code for parameters and transformed parameter block (note a little bit of messing with indexing):
```{stan output.var='priors', eval = FALSE, echo = TRUE}
parameters {
  // lambda regression parameters
  real b_gender;
  vector[3] db_mother; // order constraints mother
  real Intercept;  // temporary intercept for centered predictors

  // zi regression parameters
  vector[Kc_zi] b_zi;  // population-level effects
  real Intercept_zi;  // temporary intercept for centered predictors
}
transformed parameters {
  vector[Kc] b;  // population-level effects

  b[1] = b_gender;
  b[2] = db_mother[1];
  b[3] = db_mother[2];
  b[4] = b[2] + db_mother[3];
}
```


Now we can proceed to compute all the elements of the bayes Factor.

#### Prior

We defined used as prior for all the parameters of interest a normal distribution with mean zero and standard deviation 5: $\mathcal{N}(0, 5)$.

Thus, the resulting prior is a multivariate normal distribution with vector mean all equal to zero and covariance matrix a diagonal matrix with values 25.

```{r, echo = TRUE}
prior_mean <- c(0, 0, 0)
prior_cov <- diag(3) * 25
```

- **Prior Density Equality Constraints**  is computed as
```{r, echo = TRUE}
prior_den_eq <- mvtnorm::dmvnorm(x = 0,
                                 mean = prior_mean[2],
                                 sigma = as.matrix(prior_cov[2,2]))
prior_den_eq
```

- **Prior Conditional Probability of Inequality Constraints**  is computed as
```{r, echo = TRUE}
prior_cond_prob <- condMVNorm::pcmvnorm(
  lower = rep(0,2), upper = rep(Inf,2),
  mean = prior_mean, sigma = prior_cov,
  dependent.ind=c(1, 3), given.ind=c(2), X.given = c(0))
prior_cond_prob
```


#### Posterior

Posterior for the large sample theory, can be approximated to a multivariate normal distribution. Thus we estimate vector mean and covariance from the posteriro sample.

```{r, echo = TRUE}
post_H1 <- as.matrix(fit_H1, pars = c("db_mother[1]", "db_mother[2]", "db_mother[3]"))
post_mean <- apply(post_H1, 2, mean)
post_cov <- cov(post_H1)
```

To evaluate normal approximation consider the following plot:

```{r, plot-normal-approx}

data_plot <- data.frame(db_mother_1 = post_H1[,1],
                        db_mother_2 = post_H1[,2])
mu <- apply(post_H1,2, mean)[c(1,2)]
cov <- cov(post_H1[, c(1,2)])

data_grid <- expand.grid(s_1 = seq(0, .35, length.out=100), s_2 = seq(-.1, .25, length.out=100))
q_samp <- cbind(data_grid, prob = mvtnorm::dmvnorm(data_grid, mean = mu, sigma = cov))

ggplot(data_plot) +
  geom_density_2d(aes(x=db_mother_1, y=db_mother_2)) +
  geom_contour(data = q_samp, aes(x=s_1, y=s_2, z=prob), col = "black")+
  theme_bw()

```

- **Posterior Density Equality Constraints**  is computed as
```{r, echo = TRUE}
post_den_eq <- mvtnorm::dmvnorm(x = 0,
                                mean = post_mean[2],
                                sigma = as.matrix(post_cov[2,2]))
post_den_eq
```

- **Posterior Conditional Probability of Inequality Constraints**  is computed as
```{r, echo = TRUE}
post_cond_prob <- condMVNorm::pcmvnorm(
  lower = rep(0,2), upper = rep(Inf,2),
  mean = post_mean, sigma = post_cov,
  dependent.ind=c(1, 3), given.ind=c(2), X.given = c(0))
post_cond_prob
```

#### Resulting Bayes Factor

Thus to obtain the Bayes Factor

```{r, echo = TRUE}
BF_H1 <- (post_den_eq * post_cond_prob) / (prior_den_eq * prior_cond_prob)
BF_H1
```

The Bayes Factor is in favour of our Hypothesis. Note that this was expected as I selected hypothesis 
$$\text{Mother-Secure} = \text{Mother-Avoidonat} < \text{Mother-Anxious} < \text{Mother-Anxious-Avoidant}$$
looking to the model estimates
```{r}
brms::conditional_effects(brm_int_mother, effects = "mother")
```

### Considerations

So the method seems to work properly. I will try other hypothesis.

The limit of this approach is that we compare hypotheses but we do not estimate the actual effect. No posterior of the constrained models are obtained!

# References {-}

